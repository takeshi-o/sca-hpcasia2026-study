# 📚 Keynote: Quo Vadis Computer Architecture: Back to the Future
## SCA/HPC Asia 2026 事前勉強資料

---

## 📋 発表情報

| 項目 | 内容 |
|------|------|
| **セッション名** | Keynote 4: Quo Vadis Computer Architecture: Back to the Future |
| **日時** | 2026年1月28日（水）09:45 - 10:30 |
| **会場** | 5F Main Hall |
| **発表者** | Mateo Valero |
| **所属** | Director/Professor, Barcelona Supercomputing Center (BSC) / Technical University of Catalonia (UPC) |
| **関連度** | ⭐⭐⭐⭐⭐（AI/HPCアーキテクチャの根幹を理解する必須講演） |

### 発表概要（公式）

> 私の講演のライトモチーフは、コンピュータアーキテクチャにおける過去の進歩が今日の私たちの分野でも引き続き関連性があり、将来を決定するという命題です。現在のAIアクセラレータがシストリックアレイに基づいていること、今日のベクトルプロセッサがCrayスーパーコンピュータの影響を受けていることについて触れます。

---

## 🎯 この発表を理解するための前提知識

### 1️⃣ 「Quo Vadis」とは

**概念**: ラテン語で「どこへ行くのか？」という意味です。

```
講演タイトルの意味:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  "Quo Vadis Computer Architecture: Back to the Future"     │
│                                                             │
│  「コンピュータアーキテクチャはどこへ向かうのか？           │
│   未来へ戻れ」                                              │
│                                                             │
│  映画「バック・トゥ・ザ・フューチャー」のオマージュ        │
│  →「過去の技術に未来のヒントがある」というメッセージ      │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**講演の主旨**: 1960〜80年代に生まれた革新的なアイデア（シストリックアレイ、ベクトル処理など）が、現代のAIアクセラレータやHPCシステムの核となっている。過去を学ぶことで未来が見える。

---

### 2️⃣ コンピュータアーキテクチャとは

**概念**: コンピュータの「設計思想」と「構造」のことです。

```
コンピュータアーキテクチャの階層:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  アプリケーション（Word, ゲーム, AI学習）                   │
│           ↓                                                 │
│  プログラミング言語（Python, C++）                          │
│           ↓                                                 │
│  コンパイラ / インタプリタ                                  │
│           ↓                                                 │
│  ┌─────────────────────────────────────┐ ← ここが          │
│  │  命令セットアーキテクチャ（ISA）    │   アーキテクチャ  │
│  │  ・x86, ARM, RISC-V など            │                   │
│  └─────────────────────────────────────┘                   │
│           ↓                                                 │
│  ┌─────────────────────────────────────┐                   │
│  │  マイクロアーキテクチャ             │ ← 実装方式        │
│  │  ・パイプライン、キャッシュ など    │                   │
│  └─────────────────────────────────────┘                   │
│           ↓                                                 │
│  トランジスタ / 物理回路                                    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**なぜ重要か**: アーキテクチャの設計が、コンピュータの性能・消費電力・コストを決定します。

---

### 3️⃣ ムーアの法則とデナード・スケーリング

**概念**: 半導体産業を50年以上牽引してきた2つの「法則」です。

```
ムーアの法則（1965年〜）:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  "トランジスタ数は約18ヶ月で2倍になる"                      │
│                                                             │
│  1971年:    2,300個（Intel 4004）                           │
│  1989年: 1,200,000個（Intel 486）                           │
│  2020年: 54,000,000,000個（Apple M1）                       │
│  2024年: 208,000,000,000個（NVIDIA B200）                   │
│                                                             │
│  現在: 物理的限界に近づき、鈍化傾向                         │
└─────────────────────────────────────────────────────────────┘

デナード・スケーリング（1974年〜2006年頃）:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  "トランジスタが小さくなると、消費電力密度は一定"           │
│                                                             │
│  つまり: 小型化 → 高速化 → 同じ電力                        │
│         クロック周波数を上げれば性能UP！                    │
│                                                             │
│  2006年頃に破綻:                                            │
│  ・リーク電流の増大                                         │
│  ・熱密度の限界（ホットプレート並み）                       │
│  ・「電力の壁」「周波数の壁」                               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**現在の状況**:
- ムーアの法則: 鈍化しつつも継続（チップレット技術などで延命）
- デナード・スケーリング: 2006年頃に終焉
- → **マルチコア時代**、そして**ドメイン特化アクセラレータ時代**へ

---

### 4️⃣ 命令レベル並列性（ILP）

**概念**: 1つのプログラム内で、複数の命令を同時に実行する技術です。

```
ILP（Instruction Level Parallelism）:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【従来：順次実行】                                         │
│                                                             │
│  時間 →  1    2    3    4    5    6                        │
│  命令A: [F ] [D ] [E ] [W ]                                │
│  命令B:           [F ] [D ] [E ] [W ]                      │
│  命令C:                     [F ] [D ] [E ] [W ]            │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  【ILP：並列実行（パイプライン + スーパースカラ）】         │
│                                                             │
│  時間 →  1    2    3    4    5                             │
│  命令A: [F ] [D ] [E ] [W ]                                │
│  命令B:      [F ] [D ] [E ] [W ]                           │
│  命令C:           [F ] [D ] [E ] [W ]                      │
│                                                             │
│  F=Fetch(取得), D=Decode(解読), E=Execute(実行), W=Write   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**ILPの限界**:
- プログラム中の依存関係により、並列化できる命令数に限界
- 実際のプログラムでは ILP ≈ 2〜4 程度が現実的
- → より大きな並列性を得るには**データ並列性**や**スレッド並列性**が必要

---

### 5️⃣ アウトオブオーダー実行（Out-of-Order Execution）

**概念**: 命令を「プログラムの順序」ではなく、「実行可能になった順」に実行する技術です。

```
アウトオブオーダー実行の仕組み:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  プログラム順序:                                            │
│  1. A = B + C     ← Bの読み込み待ち                        │
│  2. D = A * 2     ← 命令1の結果待ち                        │
│  3. E = F + G     ← 命令1,2と無関係！                      │
│                                                             │
│  【インオーダー実行】                                       │
│  時間 →  1    2    3    4    5    6    7                   │
│  命令1: [待] [待] [E ] [W ]                                │
│  命令2:                     [E ] [W ]                      │
│  命令3:                               [E ] [W ]            │
│                                                             │
│  【アウトオブオーダー実行】                                 │
│  時間 →  1    2    3    4    5                             │
│  命令1: [待] [待] [E ] [W ]                                │
│  命令3:      [E ] [W ]          ← 先に実行！               │
│  命令2:                [E ] [W ]                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**Tomasuloアルゴリズム（1967年）**:
- IBM System/360 Model 91で初めて実装
- レジスタリネーミングでデータ依存を解消
- 現代のほぼ全ての高性能CPUで使用される基盤技術
- **Mateo Valero教授はこの分野の世界的権威**

---

### 6️⃣ ベクトルプロセッサ

**概念**: 同じ演算を大量のデータに一括で適用する処理方式です。

```
スカラー vs ベクトル処理:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【スカラー処理】1回に1つのデータを処理                     │
│                                                             │
│  for (i = 0; i < 1000; i++) {                              │
│      C[i] = A[i] + B[i];  // 1000回ループ                  │
│  }                                                          │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  【ベクトル処理】複数データを一括処理                       │
│                                                             │
│  VADD V_C, V_A, V_B   // 1命令で1000要素を処理             │
│                                                             │
│  ┌───┬───┬───┬───┬───┬───┬───┬───┐                        │
│  │ A0│ A1│ A2│ A3│ A4│ A5│ A6│ A7│ ← ベクトルレジスタA    │
│  └───┴───┴───┴───┴───┴───┴───┴───┘                        │
│    +   +   +   +   +   +   +   +   ← 並列加算              │
│  ┌───┬───┬───┬───┬───┬───┬───┬───┐                        │
│  │ B0│ B1│ B2│ B3│ B4│ B5│ B6│ B7│ ← ベクトルレジスタB    │
│  └───┴───┴───┴───┴───┴───┴───┴───┘                        │
│    =   =   =   =   =   =   =   =                           │
│  ┌───┬───┬───┬───┬───┬───┬───┬───┐                        │
│  │ C0│ C1│ C2│ C3│ C4│ C5│ C6│ C7│ ← 結果                 │
│  └───┴───┴───┴───┴───┴───┴───┴───┘                        │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**Cray-1（1976年）の革新**:
- 世界初の商用ベクトルスーパーコンピュータ
- ベクトルレジスタ（8本 × 64要素 × 64ビット）
- ベクトルチェイニング（パイプライン連結）
- ピーク性能: 160 MFLOPS（当時としては驚異的）

**現代への影響**:
- NEC SX-Aurora TSUBASA
- Arm SVE（Scalable Vector Extension）
- 富岳のA64FX
- Intel AVX-512

---

### 7️⃣ シストリックアレイ

**概念**: データが「心臓の拍動」のようにリズミカルに流れる並列処理アーキテクチャです。

```
シストリックアレイの動作:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  行列積 C = A × B を計算する例                              │
│                                                             │
│       ↓B列データが上から流れ込む                           │
│      ┌───┬───┬───┬───┐                                     │
│  A→  │PE │PE │PE │PE │  ← 各PEは積和演算を実行            │
│  行  ├───┼───┼───┼───┤                                     │
│  デ  │PE │PE │PE │PE │     PE = Processing Element         │
│  ー  ├───┼───┼───┼───┤          （処理要素）               │
│  タ  │PE │PE │PE │PE │                                     │
│      ├───┼───┼───┼───┤                                     │
│      │PE │PE │PE │PE │                                     │
│      └───┴───┴───┴───┘                                     │
│            ↓                                                │
│       結果Cが下から出てくる                                 │
│                                                             │
│  特徴:                                                      │
│  ・データは隣接PEにのみ流れる（長距離配線不要）            │
│  ・メインメモリへのアクセス最小化                          │
│  ・高い電力効率                                             │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**歴史**:
- 1943年: Colossus（英国の暗号解読機）で最初の使用
- 1978年: H.T. Kung と Charles Leiserson が理論を体系化
- 2016年: Google TPU で復活！

**Google TPUとシストリックアレイ**:
- TPU v1: 256×256 = 65,536 個の MAC ユニット
- データを一度ロードし、配列を流れるように処理
- メモリアクセスを最小化し、高い電力効率を実現

---

### 8️⃣ VLIW（Very Long Instruction Word）

**概念**: コンパイラが並列実行可能な命令を1つの「長い命令」にまとめる方式です。

```
VLIWの仕組み:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【従来（スーパースカラ）】ハードウェアが並列性を発見       │
│                                                             │
│  命令列: ADD, MUL, LOAD, SUB, STORE ...                    │
│            ↓                                                │
│  [複雑なハードウェアロジック]                               │
│            ↓                                                │
│  「ADD と LOAD は同時実行可能」と判断                       │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  【VLIW】コンパイラが並列性を事前に決定                     │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ スロット1 │ スロット2 │ スロット3 │ スロット4 │      │   │
│  │   ADD     │   MUL     │   LOAD    │   NOP     │      │   │
│  └─────────────────────────────────────────────────────┘   │
│              ↑                                              │
│        1つの「長い命令」（128ビット以上）                  │
│                                                             │
│  利点: ハードウェアが単純、低消費電力                       │
│  欠点: コンパイラ依存、互換性問題                           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**EPIC（Intel Itanium）**:
- VLIWの発展形としてIntelとHPが開発
- 大きなレジスタファイル（128本×64ビット）
- プレディケーション（条件付き実行）
- 結果: 商業的には失敗したが、多くの教訓を残した

**現代への影響**:
- DSP（デジタルシグナルプロセッサ）で広く採用
- AIアクセラレータの制御部で活用
- コンパイラ技術の発展に貢献

---

### 9️⃣ 混合精度演算（Mixed Precision）

**概念**: 異なる精度（ビット数）の数値形式を組み合わせて計算効率を向上させる技術です。

```
数値精度の比較:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  FP64（倍精度）: 64ビット                                   │
│  ├─符号(1)─┤────指数(11)────┤─────仮数(52)─────────────┤   │
│  範囲: ±10^308   精度: 15-16桁   用途: 科学計算            │
│                                                             │
│  FP32（単精度）: 32ビット                                   │
│  ├符号┤──指数(8)──┤────仮数(23)─────┤                      │
│  範囲: ±10^38    精度: 7桁       用途: グラフィックス      │
│                                                             │
│  FP16（半精度）: 16ビット                                   │
│  ├符号┤─指数(5)─┤──仮数(10)──┤                             │
│  範囲: ±65504   精度: 3-4桁     用途: AI推論               │
│                                                             │
│  BF16（bfloat16）: 16ビット                                 │
│  ├符号┤──指数(8)──┤─仮数(7)─┤                              │
│  範囲: ±10^38   精度: 2-3桁     用途: AI学習               │
│                                                             │
│  INT8: 8ビット整数                                          │
│  範囲: -128〜127             用途: 量子化推論               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**混合精度のメリット**:
1. **高速化**: 低精度演算は2〜16倍高速
2. **省メモリ**: 半分〜1/4のメモリで同じモデルを処理
3. **省電力**: 小さなデータ = 少ないエネルギー

**過去からの教訓**:
- 1980年代のスパコンでも異なる精度を使い分け
- 「必要な精度で計算する」という古いアイデアがAI時代に復活

---

### 🔟 ドメイン特化アーキテクチャ（DSA）

**概念**: 特定の用途に最適化された専用プロセッサです。

```
汎用 vs ドメイン特化:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【汎用CPU】                                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 何でもできるが、特定タスクでは効率5〜10%程度       │   │
│  │ 命令フェッチ・デコードのオーバーヘッドが大きい     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  【GPU】                                                    │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ グラフィックス・並列計算に特化                      │   │
│  │ 汎用性を残しつつ、並列性を最大化                    │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  【DSA（TPU, NPUなど）】                                    │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 特定ワークロード（行列積など）に完全特化           │   │
│  │ 効率90%以上を達成可能                               │   │
│  │ 柔軟性は犠牲                                        │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  例え:                                                      │
│  CPU = 万能ナイフ                                           │
│  GPU = 電動ドライバーセット                                 │
│  DSA = 寿司職人の包丁                                       │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**主なDSA**:
| 名称 | 開発元 | 用途 |
|------|--------|------|
| TPU | Google | AI学習・推論 |
| Trainium | AWS | AI学習 |
| Inferentia | AWS | AI推論 |
| Gaudi | Intel/Habana | AI学習 |
| WSE | Cerebras | 大規模AI |

---

## 📖 発表概要

### 🎯 研究の目的

Mateo Valero教授は、コンピュータアーキテクチャの50年以上の歴史を俯瞰し、過去の革新が現代のAI/HPCシステムにどのように受け継がれているかを明らかにします。

### 📊 期待される発表内容

公式アブストラクトによると、以下のトピックが取り上げられます：

1. **シストリックアレイとAIアクセラレータ**
   - 1970年代の理論が2010年代のTPUで復活
   - 「古いアイデア + 新しい技術 = ブレークスルー」

2. **ベクトルプロセッサとCray遺産**
   - Cray-1（1976年）の設計思想
   - 現代のArmベクトル拡張（SVE/SVE2）への影響
   - 富岳A64FXへの系譜

3. **混合精度とデータフォーマット**
   - 過去の精度選択の知見
   - AI時代のFP16/BF16/INT8活用
   - エネルギー効率最適化

---

## 🔬 技術的詳細

### 🧪 講演で取り上げられる技術系譜

```
コンピュータアーキテクチャの進化:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  1960年代                                                   │
│  ├── CDC 6600 (1964): スコアボード、パイプライン           │
│  └── IBM 360/91 (1967): Tomasuloアルゴリズム               │
│                                                             │
│  1970年代                                                   │
│  ├── Cray-1 (1976): ベクトルプロセッサ                     │
│  └── Kung & Leiserson (1978): シストリックアレイ理論       │
│                                                             │
│  1980-90年代                                                │
│  ├── Intel i860 (1989): VLIWアプローチ                     │
│  ├── DEC Alpha 21264 (1998): アウトオブオーダー            │
│  └── Intel Itanium (2001): EPIC                            │
│                                                             │
│  2000年代                                                   │
│  ├── マルチコア時代の到来                                  │
│  └── GPGPU（汎用GPU）の台頭                                │
│                                                             │
│  2010年代〜現在                                             │
│  ├── Google TPU (2016): シストリックアレイ復活             │
│  ├── NVIDIA Tensor Core: 混合精度行列演算                  │
│  ├── Apple M1 (2020): 高効率異種アーキテクチャ             │
│  └── 富岳 (2021): ARMベクトル拡張                          │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 📈 性能向上の歴史

| 年代 | 主な手法 | 性能向上の源泉 |
|------|---------|---------------|
| 1970年代 | ベクトル処理 | データ並列性 |
| 1980年代 | パイプライン深化 | 命令レベル並列性 |
| 1990年代 | アウトオブオーダー実行 | 動的スケジューリング |
| 2000年代 | マルチコア | スレッド並列性 |
| 2010年代〜 | DSA（ドメイン特化） | ワークロード特化 |

### 🔍 「Back to the Future」の具体例

| 過去の技術 | 復活した形態 | 用途 |
|-----------|-------------|------|
| シストリックアレイ (1978) | Google TPU (2016) | AI学習・推論 |
| ベクトルレジスタ (1976) | Arm SVE, AVX-512 | HPC, AI |
| 混合精度 (1980年代) | Tensor Core FP16/INT8 | AI学習 |
| パイプライン (1960年代) | GPU ストリーミングプロセッサ | 並列処理 |

---

## 👤 発表者プロフィール

### Mateo Valero 教授

| 項目 | 内容 |
|------|------|
| **氏名** | Mateo Valero Cortés |
| **生年** | 1952年（スペイン・アルファメン生まれ） |
| **現職** | Barcelona Supercomputing Center (BSC) 創設者・所長 |
| **学位** | マドリード工科大学 電気通信工学士 (1974), カタルーニャ工科大学 博士 (1980) |
| **専門** | コンピュータアーキテクチャ、高性能計算 |

### 主要受賞歴

| 年 | 賞名 | 授賞理由 |
|----|------|---------|
| 2007 | **Eckert-Mauchly Award** | ベクトル、マルチスレッド、VLIWへの貢献（ACM/IEEE最高賞） |
| 2009 | Harry H. Goode Award | プロセッサアーキテクチャへの貢献 |
| 2015 | **Seymour Cray Award** | ベクトル、アウトオブオーダー、マルチスレッド、VLIWへの貢献 |
| 2017 | **Charles Babbage Award** | 並列計算への貢献と欧州研究環境構築 |

### 称号

- **IEEE Fellow**
- **ACM Fellow**
- **Intel Distinguished Research Fellow**
- **ICT European Program Hall of Fame**（1983-2008年で欧州IT最重要研究者25人に選出）

### 論文・特許

- 論文数: 約700本
- 国際会議組織: 300回以上
- 招待講演: 800回以上
- 博士指導: 多数

---

## 🔗 関連研究

### 📄 主要論文・書籍

| タイトル | 著者/発表 | 概要 |
|---------|----------|------|
| Computer Architecture: A Quantitative Approach | Hennessy & Patterson | アーキテクチャのバイブル（Valero教授も頻繁に引用） |
| In-datacenter performance analysis of a tensor processing unit | Jouppi et al. (ISCA 2017) | Google TPU論文 |
| The Cray-1 Computer System | Cray Research (1976) | Cray-1の技術文書 |
| Systolic Arrays for VLSI | Kung (1982) | シストリックアレイ理論 |

### 🛠️ 関連システム

| システム名 | 開発元 | 特徴 |
|-----------|--------|------|
| MareNostrum 5 | BSC | 欧州最大級スパコン（2023年〜） |
| 富岳 | 理研/富士通 | Arm SVE搭載、Top500 1位経験 |
| NVIDIA H100 | NVIDIA | Tensor Core、FP8対応 |
| Google TPU v5p | Google | シストリックアレイ、3Dトーラス接続 |

---

## 💭 聴講のポイント

### ❓ 質問候補

| 質問 | 意図 |
|------|------|
| シストリックアレイは今後も主流であり続けるか？ | TPU以外のDSA設計動向を把握 |
| ベクトル処理とGPU SIMDの本質的な違いは？ | 設計選択の根拠を理解 |
| RISC-VベクトルエクステンションはAIにどう貢献？ | オープンアーキテクチャの将来 |
| 次の「Back to the Future」は何か？ | 復活が予想される古い技術 |
| デナード・スケーリング終焉後の電力効率改善手法は？ | 持続可能な性能向上 |
| MareNostrumの次世代計画は？ | 欧州HPC戦略 |

### 🏭 マツダAI駆動開発への示唆

| 観点 | 示唆 |
|------|------|
| **アーキテクチャ選択** | ワークロードに応じたCPU/GPU/DSAの使い分けが重要。汎用性 vs 効率のトレードオフを理解 |
| **混合精度活用** | FP32固定ではなく、BF16/FP16/INT8を積極活用。学習と推論で異なる精度戦略 |
| **ベクトル処理活用** | Arm SVE（AWS Graviton等）やAVX-512の活用でHPC/シミュレーション高速化 |
| **長期的視点** | 「流行り」ではなく「本質」を見極める。50年前の技術が今日の基盤になっている |
| **欧州連携** | BSC/EU HPCエコシステムとの連携可能性。日欧共同プロジェクトへの参画 |
| **人材育成** | アーキテクチャの基礎知識がAI時代にも重要。歴史を知ることで未来を読む |

---

## 📅 関連セッション（同カンファレンス内）

| セッション名 | 日時 | 関連性 |
|-------------|------|-------|
| **Keynote: Ultra Ethernet for next-generation AI and HPC workloads** | 1/27 09:30-10:15 | Torsten Hoefler講演、ネットワークアーキテクチャ |
| **Paper Track 4: Linear Algebra & Tensor-Core Techniques I** | 1/27 13:30-15:00 | Tensor Core、混合精度の研究発表 |
| **Paper Track 6: Linear Algebra & Tensor-Core Techniques II** | 1/27 15:30-17:00 | 行列演算最適化 |
| **Paper Track 8: Accelerators in Practice** | 1/28 11:00-12:30 | アクセラレータ実践（Cerebras、AMD MI300A等） |
| **Invited Session: Architecting the future of AI infrastructure** | 1/27 11:30-12:30 | AI基盤アーキテクチャのパネル |
| **The 8th R-CCS International Symposium** | 1/28 11:00-17:50 | 富岳NEXT議論 |

---

## 📚 参考資料

### 📖 論文・書籍

- Hennessy, J. L., & Patterson, D. A. (2019). *Computer Architecture: A Quantitative Approach* (6th ed.). Morgan Kaufmann.
- Jouppi, N. P., et al. (2017). "In-datacenter performance analysis of a tensor processing unit." ISCA '17.
- Kung, H. T. (1982). "Why systolic architectures?" *Computer*, 15(1), 37-46.

### 🌐 Webリソース

- [Barcelona Supercomputing Center 公式](https://www.bsc.es/)
- [Mateo Valero プロフィール（BSC）](https://www.bsc.es/mateo-valero)
- [MareNostrum 情報](https://bsc.es/marenostrum/marenostrum)
- [IEEE Computer Society - Mateo Valero](https://www.computer.org/profiles/mateo-valero/)
- [Computer History Museum - Cray-1](https://www.computerhistory.org/revolution/supercomputers/10/7)

### 💻 関連プロジェクト

- [RISC-V Vector Extension](https://github.com/riscv/riscv-v-spec)
- [European Processor Initiative (EPI)](https://www.european-processor-initiative.eu/)

---

## 📖 用語集（高校生向け解説付き）

| 用語 | 読み方 | 説明 |
|------|--------|------|
| **コンピュータアーキテクチャ** | こんぴゅーたあーきてくちゃ | コンピュータの「設計図」と「構造」。家の設計図が間取りや構造を決めるように、アーキテクチャがコンピュータの性能や特徴を決める。 |
| **ムーアの法則** | むーあのほうそく | 「トランジスタ数は18ヶ月で2倍になる」という経験則。1965年にIntel創業者ゴードン・ムーアが提唱。50年以上続いたが、最近は鈍化傾向。 |
| **デナード・スケーリング** | でなーどすけーりんぐ | 「トランジスタを小さくしても消費電力密度は一定」という法則。これが成り立つ間はクロック速度を上げ続けられた。2006年頃に限界に達し、マルチコア時代へ移行。 |
| **ILP** | アイエルピー | Instruction Level Parallelism（命令レベル並列性）。1つのプログラム内で複数の命令を同時実行する技術。スーパーマーケットで複数のレジを同時に開くイメージ。 |
| **アウトオブオーダー実行** | あうとおぶおーだーじっこう | 命令を「書かれた順」ではなく「実行可能になった順」に処理する技術。待ち時間を有効活用して性能向上。 |
| **Tomasuloアルゴリズム** | とますろあるごりずむ | 1967年にIBMで発明されたアウトオブオーダー実行の基礎アルゴリズム。現代のほぼ全ての高性能CPUで使用されている。 |
| **ベクトルプロセッサ** | べくとるぷろせっさ | 同じ計算を大量のデータに一括適用する処理装置。1000人分のテストを1問ずつ採点するのではなく、1問目を全員分一気に採点するイメージ。 |
| **Cray-1** | くれいわん | 1976年に登場した伝説的スーパーコンピュータ。ベクトル処理を商用化し、スパコン時代を切り開いた。Seymour Crayが設計。 |
| **シストリックアレイ** | しすとりっくあれい | 「心臓の拍動」のようにデータが規則正しく流れる並列処理構造。Google TPUで採用され、AI時代に復活した。 |
| **TPU** | ティーピーユー | Tensor Processing Unit。Google開発のAI専用チップ。シストリックアレイで行列演算を超高速処理。 |
| **VLIW** | ブイリウ | Very Long Instruction Word。複数の操作を1つの「長い命令」にまとめて同時実行する方式。コンパイラが並列性を決定。 |
| **EPIC** | エピック | Explicitly Parallel Instruction Computing。VLIWの発展形。Intel Itaniumで採用されたが商業的には失敗。 |
| **混合精度** | こんごうせいど | 計算に使う数値の精度（ビット数）を場面に応じて使い分ける技術。重要な計算は高精度、それ以外は低精度で高速化。 |
| **FP32** | エフピーさんじゅうに | 32ビット浮動小数点数。「単精度」とも呼ばれ、約7桁の精度。一般的なグラフィックスや計算に使用。 |
| **FP16** | エフピーじゅうろく | 16ビット浮動小数点数。「半精度」とも呼ばれ、約3-4桁の精度。AI推論で広く使用。 |
| **BF16** | ビーエフじゅうろく | bfloat16。Google開発の16ビット形式。FP32と同じ広い表現範囲を持ち、AI学習で人気。 |
| **INT8** | インテイト | 8ビット整数。量子化されたAIモデルで使用。メモリと計算を大幅に削減。 |
| **DSA** | ディーエスエー | Domain Specific Architecture（ドメイン特化アーキテクチャ）。特定の用途に最適化された専用チップ。汎用CPUより効率的。 |
| **GPU** | ジーピーユー | Graphics Processing Unit。元は画像処理用だが、並列計算能力を活かしてAI/HPCで活躍。 |
| **Tensor Core** | てんそるこあ | NVIDIAのGPUに搭載された行列演算専用ユニット。混合精度で超高速。 |
| **パイプライン** | ぱいぷらいん | 命令処理を複数ステージに分割し、流れ作業で効率化する技術。工場の組立ラインと同じ発想。 |
| **スーパースカラ** | すーぱーすから | 1クロックで複数の命令を発行・実行するプロセッサ設計。複数のレジを同時に開くスーパーマーケット。 |
| **マルチコア** | まるちこあ | 1つのチップに複数のCPUコアを搭載する設計。デナード・スケーリング終焉後の主流。 |
| **BSC** | ビーエスシー | Barcelona Supercomputing Center。Mateo Valero教授が創設したスペインの国立スパコンセンター。 |
| **MareNostrum** | まれのすとるむ | BSCのスーパーコンピュータ名。ラテン語で「我らの海」（地中海）の意味。教会内に設置されている。 |
| **FLOPS** | フロップス | Floating Point Operations Per Second。1秒間に実行できる浮動小数点演算回数。スパコン性能の指標。 |
| **レジスタ** | れじすた | CPU内部の超高速メモリ。計算に使うデータを一時的に保持。数十〜数百個程度と少ないが最速。 |
| **キャッシュ** | きゃっしゅ | CPUとメインメモリの間に置かれる高速メモリ。よく使うデータを近くに置いて高速化。 |
| **富岳** | ふがく | 理研と富士通が開発した日本のスーパーコンピュータ。Arm SVE搭載でTop500 1位を獲得（2020-2021年）。 |
| **RISC-V** | りすくふぁいぶ | オープンソースの命令セットアーキテクチャ。誰でも自由に使えるCPU設計仕様。 |
| **SVE** | エスブイイー | Scalable Vector Extension。Arm社のベクトル拡張命令。富岳やAWS Gravitonで使用。 |

---

*作成日: 2025-12-25*
*SCA/HPC Asia 2026 事前勉強資料*
