# 📚 Ultra Ethernet for next-generation AI and HPC workloads
## SCA/HPC Asia 2026 事前勉強資料

---

## 📋 発表情報

| 項目 | 内容 |
|------|------|
| **セッション名** | Keynote: Ultra Ethernet for next-generation AI and HPC workloads |
| **日時** | 2026年1月27日（火）09:30 - 10:15 |
| **発表者** | Torsten Hoefler |
| **所属** | Professor, ETH Zurich, Switzerland |
| **会場** | 5F Main Hall |
| **関連度** | ⭐⭐⭐⭐⭐（AI/HPC向けネットワーク技術の最前線） |

---

## 🎯 この発表を理解するための前提知識

### 1️⃣ インターコネクト（Interconnect）とは何か

コンピュータ同士を接続して通信させる技術のことです。スーパーコンピュータやAI学習クラスタでは、数千〜数万台のコンピュータが協力して計算を行います。

```
┌─────────────────────────────────────────────────────────────────┐
│                    AIトレーニングクラスタの例                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌─────┐    ┌─────┐    ┌─────┐    ┌─────┐                     │
│   │GPU 1│    │GPU 2│    │GPU 3│    │GPU 4│  ← 1台のサーバー     │
│   └──┬──┘    └──┬──┘    └──┬──┘    └──┬──┘                     │
│      │          │          │          │                         │
│      └──────────┴──────────┴──────────┘                         │
│                       │                                          │
│                  NIC（ネットワークカード）                        │
│                       │                                          │
│   ════════════════════╪═══════════════════════════════════════  │
│                       │         ↑ インターコネクト               │
│   ════════════════════╪═══════════════════════════════════════  │
│                       │                                          │
│   ┌─────┐    ┌─────┐    ┌─────┐    ┌─────┐                     │
│   │GPU 5│    │GPU 6│    │GPU 7│    │GPU 8│  ← 別のサーバー      │
│   └─────┘    └─────┘    └─────┘    └─────┘                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**日常的な比喩**: インターコネクトは「高速道路」のようなものです。各コンピュータは「街」で、計算結果（荷物）を運ぶトラックが走る道路がインターコネクトです。道路が渋滞すると荷物が届かず、全体の作業が遅れます。

---

### 2️⃣ Ethernet（イーサネット）の基礎

Ethernetは、世界で最も普及しているネットワーク技術です。家庭のWi-Fiルーターから、企業のオフィスネットワーク、データセンターまで幅広く使われています。

```
┌─────────────────────────────────────────────────────────────────┐
│                    Ethernet の歴史と進化                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1973年  ──→  1995年  ──→  2010年  ──→  2020年  ──→  2025年    │
│                                                                 │
│  10 Mbps     100 Mbps    10 Gbps    100 Gbps    400 Gbps      │
│  (3MB/s)    (12.5MB/s)   (1.25GB/s)  (12.5GB/s)  (50GB/s)     │
│                                                                 │
│  ┌───┐       ┌───┐       ┌───┐       ┌───┐       ┌───┐        │
│  │   │       │   │       │███│       │███│       │███│        │
│  │   │       │   │       │███│       │███│       │███│        │
│  │   │       │   │       │███│       │███│       │███│        │
│  │   │       │▒▒▒│       │███│       │███│       │███│        │
│  │   │       │███│       │███│       │███│       │███│        │
│  └───┘       └───┘       └───┘       └───┘       └───┘        │
│    ↑           ↑           ↑           ↑           ↑          │
│  黎明期      普及期      データセンター   クラウド     AI時代    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**Ethernetの特徴**:
- **オープン標準**: 誰でも使える公開仕様
- **低コスト**: 大量生産により価格が下がっている
- **相互運用性**: 異なるベンダーの機器が接続可能
- **柔軟性**: 様々な用途に対応

---

### 3️⃣ InfiniBand（インフィニバンド）との違い

HPCやAI分野では、InfiniBandという専用のネットワーク技術が長年使われてきました。

```
┌─────────────────────────────────────────────────────────────────┐
│                 InfiniBand vs Ethernet 比較                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  観点            InfiniBand           Ethernet（従来）          │
│  ─────────────────────────────────────────────────────────────  │
│  遅延（レイテンシ）   ～1μs（非常に低い）   ～50μs（やや高い）    │
│  帯域幅            400Gbps              400Gbps                │
│  信頼性            ロスレス（損失なし）   ベストエフォート        │
│  コスト            高い                 低い                    │
│  ベンダー          NVIDIA独占           多数（オープン）         │
│  市場シェア(AI)    ～80%（2023年）       ～20%（2023年）         │
│                                                                 │
│  ┌────────────────────────────────────────────────────────────┐ │
│  │  Ultra Ethernet の目標:                                    │ │
│  │  「Ethernetの低コスト・オープン性」＋「InfiniBandの高性能」  │ │
│  └────────────────────────────────────────────────────────────┘ │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**日常的な比喩**:
- InfiniBandは「専用高速鉄道」（新幹線）のようなもの。速くて信頼性が高いが、建設コストが高く、特定の会社しか運営できない。
- Ethernetは「一般道路」のようなもの。どこにでもあって安いが、渋滞しやすい。
- Ultra Ethernetは「スマートハイウェイ」を目指す。一般道路のインフラを使いながら、新幹線並みの速度と信頼性を実現しようとしている。

---

### 4️⃣ RDMA（Remote Direct Memory Access）

RDMAは、ネットワーク越しに直接メモリにアクセスする技術です。

```
┌─────────────────────────────────────────────────────────────────┐
│                  従来の通信 vs RDMA                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  【従来の通信（TCP/IP）】                                        │
│                                                                 │
│  アプリケーション                      アプリケーション          │
│       │                                     ▲                   │
│       ▼                                     │                   │
│  ┌─────────┐                          ┌─────────┐              │
│  │ユーザー空間│ ← コピー ①             │ユーザー空間│ ← コピー ④ │
│  └────┬────┘                          └────▲────┘              │
│       │                                     │                   │
│  ┌────▼────┐                          ┌────┴────┐              │
│  │カーネル空間│ ← CPU処理               │カーネル空間│ ← CPU処理 │
│  └────┬────┘                          └────▲────┘              │
│       │                                     │                   │
│  ┌────▼────┐  コピー ②   ネットワーク  ┌────┴────┐ コピー ③    │
│  │   NIC   │ ─────────→ ═══════════ ─→│   NIC   │              │
│  └─────────┘                          └─────────┘              │
│                                                                 │
│  問題: CPUの介入が必要、メモリコピーが4回発生 → 遅い！           │
│                                                                 │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  【RDMA通信】                                                   │
│                                                                 │
│  アプリケーション                      アプリケーション          │
│  ┌─────────┐                          ┌─────────┐              │
│  │メモリ領域│ ━━━━━━━━━━━━━━━━━━━━━━→│メモリ領域│              │
│  └────┬────┘    ↑ 直接転送！            └─────────┘              │
│       │         （CPUをバイパス）                               │
│  ┌────▼────┐                          ┌─────────┐              │
│  │RDMA NIC │ ═══════════════════════→│RDMA NIC │              │
│  └─────────┘                          └─────────┘              │
│                                                                 │
│  利点: CPUを使わない、コピー不要 → 超低遅延！                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**なぜRDMAが重要か**:
- AI学習では、数千台のGPU間で頻繁にデータをやり取りする
- 従来の方法では、1回のデータ転送に50マイクロ秒かかる
- RDMAなら1〜2マイクロ秒で完了
- 1日の学習で数十億回の通信が発生するため、この差は巨大

---

### 5️⃣ 集団通信（Collective Communication）と AllReduce

AIの分散学習では、全てのGPUが計算結果を共有する必要があります。

```
┌─────────────────────────────────────────────────────────────────┐
│                    AllReduce 操作の例                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  【各GPUが持つ勾配（計算結果）】                                 │
│                                                                 │
│   GPU 0: [1, 2, 3]                                              │
│   GPU 1: [4, 5, 6]                                              │
│   GPU 2: [2, 3, 4]                                              │
│   GPU 3: [3, 2, 1]                                              │
│                                                                 │
│            ↓ AllReduce（合計を計算して全員に配布）              │
│                                                                 │
│  【AllReduce後：全GPUが同じ結果を持つ】                          │
│                                                                 │
│   GPU 0: [10, 12, 14]  ← 1+4+2+3=10, 2+5+3+2=12, 3+6+4+1=14   │
│   GPU 1: [10, 12, 14]                                           │
│   GPU 2: [10, 12, 14]                                           │
│   GPU 3: [10, 12, 14]                                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────┐
│                Ring AllReduce アルゴリズム                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│          ┌─────┐                                                │
│          │GPU 0│                                                │
│          └──┬──┘                                                │
│       ↗         ↘                                              │
│   ┌──┴──┐       ┌──┴──┐                                        │
│   │GPU 3│       │GPU 1│                                        │
│   └──┬──┘       └──┬──┘                                        │
│       ↖         ↙                                              │
│          ┌──┴──┐                                                │
│          │GPU 2│                                                │
│          └─────┘                                                │
│                                                                 │
│  リング状にデータを回しながら集約                                │
│  → 通信量がGPU数に依存しない効率的なアルゴリズム                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**日常的な比喩**:
クラスの生徒全員が自分の答えを持っていて、「全員の答えの合計」を全員が知りたい場合を考えてください。
- 単純な方法：全員が先生に答えを渡し、先生が合計して全員に伝える（先生がボトルネック）
- Ring AllReduce：隣の人に答えを渡しながら、順番に足していく。一周すると全員が合計を知っている

---

### 6️⃣ パケット損失（Packet Loss）と輻輳制御（Congestion Control）

ネットワークが混雑すると、データの一部が失われることがあります。

```
┌─────────────────────────────────────────────────────────────────┐
│                    パケット損失の問題                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  送信側                スイッチ                受信側           │
│  ┌────┐               ┌────┐                ┌────┐            │
│  │    │──[パケット1]─→│    │──[パケット1]──→│    │            │
│  │    │──[パケット2]─→│    │──[パケット2]──→│    │            │
│  │    │──[パケット3]─→│ ✗ │    （混雑で損失）│    │            │
│  │    │──[パケット4]─→│    │──[パケット4]──→│    │            │
│  └────┘               └────┘                └────┘            │
│                          ↓                                      │
│                    バッファ溢れ                                 │
│                                                                 │
│  問題: パケット3が失われた！                                     │
│  対処: タイムアウトを待って再送信 → 遅延が発生                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**輻輳制御の手法**:

| 手法 | 説明 | 特徴 |
|------|------|------|
| **PFC** (Priority Flow Control) | 混雑時に「ちょっと待って」信号を送る | ロスレス、但しデッドロックの危険 |
| **ECN** (Explicit Congestion Notification) | パケットに「混雑中」マークを付ける | 事前警告、損失防止 |
| **パケットトリミング** | 混雑時にデータ部分だけ捨て、ヘッダーは送る | Ultra Ethernet の革新技術 |

---

### 7️⃣ Ultra Ethernet の革新技術

Ultra Ethernetは2025年6月に仕様1.0がリリースされた、最新のネットワーク技術です。

```
┌─────────────────────────────────────────────────────────────────┐
│              Ultra Ethernet の主要イノベーション                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ① パケットトリミング（Packet Trimming）                        │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  従来: 混雑 → パケット全体を破棄 → タイムアウトまで待機          │
│                                                                 │
│  ┌──────────────────────────────────────┐                       │
│  │ ヘッダー │      データ（ペイロード）     │ ← パケット全体     │
│  └──────────────────────────────────────┘                       │
│       ↓ 混雑発生                                                │
│      ✗ 全て破棄                                                 │
│                                                                 │
│  Ultra Ethernet: 混雑 → データだけ破棄、ヘッダーは送信          │
│                                                                 │
│  ┌──────────────────────────────────────┐                       │
│  │ ヘッダー │      データ（ペイロード）     │                    │
│  └──────────────────────────────────────┘                       │
│       ↓ 混雑発生                                                │
│  ┌──────────┐                                                   │
│  │ ヘッダー │ ← ヘッダーだけ送信（トリミング）                  │
│  └──────────┘                                                   │
│       ↓                                                         │
│  受信側:「パケット3のデータが来てない！すぐ再送して！」          │
│       ↓                                                         │
│  即座に再送信要求 → タイムアウトを待たずに回復                   │
│                                                                 │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  ② ロッシー動作（Lossy Operation）                              │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  従来のロスレスネットワーク:                                     │
│  ┌────┐   PAUSE!   ┌────┐   PAUSE!   ┌────┐                    │
│  │    │ ←───────── │    │ ←───────── │    │ ← パケット待ち     │
│  └────┘            └────┘            └────┘                    │
│  問題: 1箇所の停止が全体に波及（Head-of-Line Blocking）          │
│                                                                 │
│  Ultra Ethernet のロッシー動作:                                  │
│  ┌────┐            ┌────┐            ┌────┐                    │
│  │    │ ──────────→│    │ ──────────→│    │                    │
│  └────┘            └────┘  ↓ 損失    └────┘                    │
│                         [即座に検知・再送]                       │
│  利点: 1箇所の問題が他に影響しない                               │
│                                                                 │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  ③ ハードウェアオフロード型ランデブープロトコル                  │
│  ─────────────────────────────────────────────────────────────  │
│                                                                 │
│  送信側              NIC（ハードウェア）           受信側        │
│  ┌────┐            ┌────────────────┐           ┌────┐        │
│  │    │──「送りたい」→│                │──「準備OK?」─→│    │        │
│  │    │              │  バッファ確認  │              │    │        │
│  │    │              │  自動処理      │←「OK、送って」─│    │        │
│  │    │←─「送信開始」─│                │              │    │        │
│  └────┘            └────────────────┘           └────┘        │
│                                                                 │
│  CPUを介さずにNICが自動でバッファ調整 → 超低遅延                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 📖 発表概要

### 🎯 研究の目的

Ultra Ethernet Consortiumは、AIおよびハイパフォーマンスコンピューティング（HPC）向けのEthernet基盤インターコネクトを再定義することを目指しています。本講演では、2025年6月にリリースされた仕様1.0の技術的な詳細と、次世代コンピューティングにおける変革的な可能性について解説されます。

### 📊 期待される発表内容

1. **HPCおよびAIワークロードのネットワーキング要件分析**
   - 大規模言語モデル（LLM）学習時の通信パターン
   - 勾配同期における帯域幅と遅延の要件

2. **Ultra Ethernet の主要イノベーション**
   - ロッシー動作（トリミングあり・なし両方）
   - 完全ハードウェアオフロード型ランデブープロトコル
   - マルチパス輻輳制御とパケットスプレー

3. **アーキテクチャの進歩と技術的ハイライト**
   - 効率性、スケーラビリティ、パフォーマンスの向上
   - InfiniBandとの比較優位性

---

## 🔬 技術的詳細

### 🧪 Ultra Ethernet 1.0 仕様の概要

Ultra Ethernet 1.0は560ページ以上の包括的な仕様書であり、以下の層を統合的に定義しています：

| 層 | 内容 |
|-----|------|
| **トランスポート層** | 新しいRDMAプロトコル（UET） |
| **ネットワーク層** | マルチパスルーティング、ECMP |
| **スイッチ層** | パケットトリミング、ECN |
| **NIC層** | ハードウェアオフロード、リオーダリング |
| **物理層** | 400G/800G対応、光ケーブル |

### 📈 性能指標

| 項目 | Ultra Ethernet | InfiniBand NDR |
|------|----------------|----------------|
| 遅延（小メッセージ） | サブマイクロ秒級 | ～1μs |
| 帯域幅 | 400Gbps（800G準備中） | 400Gbps |
| TCO削減 | 15-45%（IB比） | 基準 |
| ベンダーロックイン | なし | あり（NVIDIA） |

### 🔍 プロファイル別機能

Ultra Ethernetは3つのプロファイルを提供：

```
┌─────────────────────────────────────────────────────────────────┐
│                  Ultra Ethernet プロファイル                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────────┐                                            │
│  │    AI Base      │ ← 分散推論・学習の基本機能                 │
│  │  ───────────────│                                            │
│  │  ・基本RDMA     │                                            │
│  │  ・集団通信     │                                            │
│  └────────┬────────┘                                            │
│           │                                                     │
│  ┌────────▼────────┐                                            │
│  │    AI Full      │ ← AI向け拡張機能                          │
│  │  ───────────────│                                            │
│  │  ・Deferrable Send                                           │
│  │  ・タグ付き送信  │                                            │
│  │  ・拡張アトミック│                                            │
│  └────────┬────────┘                                            │
│           │                                                     │
│  ┌────────▼────────┐                                            │
│  │      HPC        │ ← HPC向けフル機能                         │
│  │  ───────────────│                                            │
│  │  ・高度なタグセマンティクス                                   │
│  │  ・完全ランデブーサポート                                     │
│  │  ・追加アトミック操作                                         │
│  └─────────────────┘                                            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 👤 発表者プロフィール

| 項目 | 内容 |
|------|------|
| **氏名** | Torsten Hoefler（トルステン・ヘフラー） |
| **現職** | スイス連邦工科大学チューリッヒ校（ETH Zurich）教授 |
| **役職** | Scalable Parallel Computing Laboratory ディレクター |
| **兼職** | スイス国立スーパーコンピューティングセンター（CSCS）AI/ML チーフアーキテクト |
| **学位** | Ph.D. in Computer Science, Indiana University |
| **専門分野** | 高性能コンピューティング、並列計算、MPI、AI分散学習 |

### 🏆 受賞歴

| 年 | 賞 | 概要 |
|-----|-----|------|
| **2024** | ACM Prize in Computing | HPC・AI革命への根本的貢献 |
| **2022** | IEEE CS Sidney Fernbach Award | HPCアプリケーションへの貢献 |
| **2019** | ACM Gordon Bell Prize | HPCにおける卓越した業績 |
| - | Max Planck-Humboldt Medal | 中堅科学者への優秀賞 |
| - | ISC Jack Dongarra Award | HPCコミュニティへの貢献 |

### 📚 主要な貢献

1. **MPI-3標準への貢献**
   - 「Collective Operations」「Process Topologies」ワーキンググループ議長
   - 非同期集団通信（Iallreduce, Iallgather等）の設計

2. **3D並列化の提唱**
   - データ並列、パイプライン並列、演算子並列の統合
   - 現代AI学習インフラの基盤概念

3. **Best Paper Awards**
   - SC（Supercomputing）: 2010, 2013, 2014, 2019, 2022, 2023, 2024
   - その他多数の国際会議

---

## 🔗 関連研究

### 📄 主要論文

| 論文タイトル | 著者 | 発表年 | 概要 |
|-------------|------|--------|------|
| Demystifying Parallel and Distributed Deep Learning | T. Ben-Nun, T. Hoefler | 2019 | 分散深層学習の包括的解説 |
| Implementation and Performance Analysis of Non-Blocking Collective Operations for MPI | T. Hoefler et al. | 2007 | 非同期集団通信の実装 |
| Ultra Ethernet's Design Principles and Architectural Innovations | UEC | 2025 | Ultra Ethernet技術論文 |

### 🛠️ 関連ツール・製品

| ツール/製品 | 提供元 | 概要 |
|------------|--------|------|
| Pensando Pollara 400 | AMD | Ultra Ethernet対応NIC（最初の製品） |
| Etherlink スイッチ | Arista | UEC 1.0対応スイッチ |
| NCCL | NVIDIA | GPU集団通信ライブラリ |
| Horovod | Uber → LF AI | 分散深層学習フレームワーク |

---

## 💭 聴講のポイント

### ❓ 質問候補

| 質問 | 意図 |
|------|------|
| Ultra Ethernetは既存のRoCEv2インフラと後方互換性がありますか？ | 既存投資の保護可能性を確認 |
| パケットトリミングのオーバーヘッドはどの程度ですか？ | 実装コストの見積もり |
| InfiniBandからの移行パスはどのように考えていますか？ | 実務的な導入計画への示唆 |
| 800Gbps対応の時期はいつ頃を想定していますか？ | 将来のロードマップ確認 |
| 日本のスーパーコンピュータ（富岳NEXTなど）への適用可能性は？ | 国内HPC環境への展開可能性 |

### 🏭 マツダAI駆動開発への示唆

| 示唆 | 詳細 |
|------|------|
| **GPUクラスタ構築コスト削減** | InfiniBandの代わりにUltra Ethernetを採用することで、15-45%のTCO削減が期待できる |
| **ベンダーロックイン回避** | NVIDIA以外の選択肢が広がり、調達の柔軟性が向上 |
| **既存ネットワークインフラ活用** | 企業内のEthernetインフラを活用してAI学習環境を構築可能 |
| **スケーラビリティ確保** | 将来的なGPU増設時にもスムーズに拡張可能 |
| **分散学習効率の向上** | 低遅延通信により、大規模モデル学習の時間短縮が期待 |

---

## 📅 関連セッション（同カンファレンス内）

| セッション名 | 日時 | 発表者 | 関連度 |
|-------------|------|--------|--------|
| Ethernet for HPC/AI clusters | 1/27 13:30-17:00 | Mohan Kalkunte (Broadcom) | ⭐⭐⭐⭐⭐ |
| Architecting the future of AI infrastructure | 1/27 11:30-12:30 | Eric Van Hensbergen (Arm) | ⭐⭐⭐⭐ |
| Vision and Strategy: HPC Centers | 1/27-28 | Taisuke Boku, Andrew Rohl | ⭐⭐⭐ |
| Paper Track 10: MPI, Topology & Contention | 1/28 13:30-15:00 | - | ⭐⭐⭐⭐ |

---

## 📚 参考資料

### 📖 論文・プレプリント

- [Ultra Ethernet's Design Principles and Architectural Innovations (arXiv)](https://arxiv.org/html/2508.08906v1)
- [Demystifying Parallel and Distributed Deep Learning (ACM)](https://dl.acm.org/doi/10.1145/3320060)
- [An Allreduce Algorithm and Network Co-design for Large-Scale Training (IEEE)](https://ieeexplore.ieee.org/document/9499662/)

### 🌐 Webリソース

- [Ultra Ethernet Consortium 公式サイト](https://ultraethernet.org/)
- [UEC 1.0 仕様書](https://ultraethernet.org/ultra-ethernet-consortium-uec-launches-specification-1-0-transforming-ethernet-for-ai-and-hpc-at-scale/)
- [Intersect360 Research White Paper: UEC 1.0](https://ultraethernet.org/wp-content/uploads/sites/20/2025/06/UEC1.0Whitepaper.pdf)
- [Torsten Hoefler ホームページ](https://htor.inf.ethz.ch/)
- [ETH Zurich ニュース: ACM Prize in Computing](https://ethz.ch/en/news-and-events/eth-news/news/2025/03/super-fast-computers-for-ai-torsten-hoefler-awarded-acm-prize.html)

### 💻 GitHub

- [NCCL (NVIDIA Collective Communications Library)](https://github.com/NVIDIA/nccl)
- [Horovod](https://github.com/horovod/horovod)
- [OpenMPI](https://github.com/open-mpi/ompi)

---

## 📖 用語集（高校生向け解説付き）

| 用語 | 読み方 | 説明 |
|------|--------|------|
| **Ultra Ethernet** | ウルトラ・イーサネット | 2025年に策定された、AIとHPC向けに最適化された新しいEthernet規格。従来のEthernetの「安さ」「普及」とInfiniBandの「速さ」「信頼性」の両方を実現しようとする技術。スマートフォンの4Gから5Gへの進化のような飛躍を目指している。 |
| **HPC** | エイチピーシー | High Performance Computing（ハイパフォーマンス・コンピューティング）の略。天気予報、創薬シミュレーション、宇宙開発など、膨大な計算が必要な分野で使われるスーパーコンピュータのこと。 |
| **Ethernet** | イーサネット | 世界で最も普及しているネットワーク技術。家のWi-Fiルーターからデータセンターまで、ほぼ全てのコンピュータ接続に使われている。1973年に発明され、50年以上進化を続けている。 |
| **InfiniBand** | インフィニバンド | HPCやAI向けの高速ネットワーク技術。非常に低遅延で信頼性が高いが、主にNVIDIAが提供しており、コストが高い。現在AIクラスタの約80%で使用されている。 |
| **RDMA** | アールディーエムエー | Remote Direct Memory Access。別のコンピュータのメモリに直接アクセスする技術。手紙（データ）を郵便局（CPU）を経由せず、直接相手のポスト（メモリ）に届けるようなイメージ。超高速通信を可能にする。 |
| **レイテンシ（遅延）** | れいてんしー | データが送信されてから届くまでの時間。電話で話すとき、相手の声が遅れて聞こえると会話しにくいように、コンピュータ間の通信でも遅延が大きいと処理が遅くなる。マイクロ秒（100万分の1秒）単位で計測される。 |
| **帯域幅** | たいいきはば | 1秒間に送れるデータの量。水道管の太さのようなもの。太い管なら一度にたくさんの水が流れる。400Gbpsなら1秒間に400ギガビット（約50ギガバイト）のデータを送れる。 |
| **パケット** | ぱけっと | ネットワーク上でデータを運ぶ際の「小包」。大きなデータは小さなパケットに分割されて送られ、受信側で元に戻される。宅配便で大きな荷物を小分けにして送るようなイメージ。 |
| **パケットトリミング** | ぱけっと・とりみんぐ | Ultra Ethernetの革新技術。ネットワークが混雑したとき、パケットのデータ部分だけを捨て、ヘッダー（宛先情報）は送り続ける。受信側は「荷物が来てない」とすぐ分かるので、再送信を早く要求できる。 |
| **ロスレス** | ろすれす | データが一切失われない通信方式。銀行振込のように、1円も欠けずに届くことが保証される。ただし、混雑時に全体が止まることがある。 |
| **ロッシー** | ろっしー | データの一部が失われる可能性がある通信方式。動画配信のように、少しのデータ欠けは許容して全体の流れを優先する。Ultra Ethernetはロッシーでも高速復旧できる仕組みを持つ。 |
| **AllReduce** | オール・リデュース | 全てのコンピュータが持つデータを集計して、結果を全員に配布する操作。クラス全員のテストの点数を合計して、その合計を全員に教えるようなもの。AI学習で最も頻繁に使われる通信パターン。 |
| **MPI** | エムピーアイ | Message Passing Interface。複数のコンピュータが協力して計算するための「共通言語」。LINEのグループチャットのように、メッセージを送り合って情報を共有する。 |
| **3D並列化** | さんでぃー・へいれつか | AI学習を効率化する手法。データ並列（同じ計算を分担）、パイプライン並列（処理を分業）、演算子並列（1つの計算を分割）を組み合わせる。工場の流れ作業を3次元的に最適化するイメージ。 |
| **ECN** | イーシーエヌ | Explicit Congestion Notification。ネットワークが混雑しそうなとき、パケットに「混んでます」マークを付ける仕組み。高速道路の渋滞情報のように、事前に警告を出して速度を調整させる。 |
| **PFC** | ピーエフシー | Priority Flow Control。混雑時に「ちょっと待って」信号を送って、データ送信を一時停止させる。交差点の信号機のように、流れを制御してデータ損失を防ぐ。 |
| **ランデブープロトコル** | らんでぶー・ぷろとこる | 送信側と受信側が「準備OK?」「OK、送って」とやり取りしてからデータを送る方式。待ち合わせ（ランデブー）してから荷物を渡すイメージ。バッファ溢れを防げるが、やり取りの分だけ時間がかかる。 |
| **TCO** | ティーシーオー | Total Cost of Ownership。購入価格だけでなく、運用コスト、電気代、保守費用なども含めた総所有コスト。車を買うとき、本体価格だけでなくガソリン代や車検代も考慮するようなもの。 |
| **UEC** | ユーイーシー | Ultra Ethernet Consortium。Ultra Ethernet規格を策定している業界団体。Cisco、Arista、HPE、Intel、AMD、Broadcomなど主要ネットワーク企業が参加。2023年に設立。 |
| **NIC** | ニック | Network Interface Card。コンピュータをネットワークに接続するためのカード（ハードウェア）。コンピュータの「電話機」のようなもので、これがないと通信できない。 |
| **輻輳** | ふくそう | ネットワークが混雑している状態。通勤ラッシュで電車が満員になるように、データが集中しすぎて流れが悪くなること。 |
| **スケーラビリティ** | すけーらびりてぃ | システムの規模を大きくしても性能が落ちにくい性質。10台で動くシステムを1000台に増やしても同じ効率で動けるかどうか。エスカレーターは人数が増えても速度が変わらないが、エレベーターは待ち時間が増える。 |
| **GPU** | ジーピーユー | Graphics Processing Unit。元々は画像処理用だったが、AI学習に最適な並列計算能力を持つ。1つのCPUが「優秀な1人の計算機」なら、GPUは「普通だけど1000人の計算機」。 |

---

*作成日: 2024年12月24日*
*SCA/HPC Asia 2026 事前勉強資料*
