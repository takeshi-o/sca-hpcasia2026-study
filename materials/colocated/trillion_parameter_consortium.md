# 📚 Trillion Parameter Consortium (TPC)
## SCA/HPC Asia 2026 事前勉強資料

---

## 📋 発表情報

| 項目 | 内容 |
|------|------|
| **セッション名** | Co-located Event: Trillion Parameter Consortium (TPC) |
| **日時** | 2026年1月27日（火）11:30-17:00、1月28日（水）11:00-17:00（2日間開催） |
| **会場** | グランキューブ大阪（大阪国際会議場） |
| **形式** | 併催イベント（ワークショップ・討論） |
| **共同議長** | Rio Yokota（横田理央）/ Charlie Catlett |
| **所属** | Institute of Science Tokyo / RIKEN R-CCS / Argonne National Laboratory |
| **関連度** | ⭐⭐⭐⭐⭐（科学向け大規模AIの国際最前線） |

---

## 🎯 この発表を理解するための前提知識

### 1️⃣ 大規模言語モデル（LLM）とパラメータ数

AIモデルの「パラメータ」とは、学習によって調整される数値のことです。

```
┌────────────────────────────────────────────────────────────────┐
│                 AIモデルのパラメータ数の進化                     │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  パラメータ数                                                   │
│  (対数スケール)                                                 │
│       ↑                                                        │
│  1兆  │                              ┌─────┐                  │
│  (10^12)                             │GPT-4 │ ← 1.8兆推定     │
│       │                              └─────┘                  │
│       │                        ┌─────────┐                    │
│  1000億│                        │ GPT-3   │ 1750億            │
│       │                        └─────────┘                    │
│       │                  ┌─────────┐                          │
│  100億 │                  │ Llama 3 │ 700億                    │
│       │                  └─────────┘                          │
│       │            ┌─────────┐                                │
│  10億  │            │  BERT   │ 3億                           │
│       │            └─────────┘                                │
│       └────────────────────────────────────────────→ 時間     │
│           2018      2020      2022      2024                   │
│                                                                │
│  【なぜパラメータ数が重要？】                                   │
│  ● パラメータ数が多いほど、複雑なパターンを学習可能             │
│  ● 一般的に性能が向上（スケーリング則）                        │
│  ● ただし、学習に必要な計算資源も指数関数的に増加              │
│                                                                │
│  【1兆パラメータの意味】                                        │
│  ● 1,000,000,000,000個の調整可能な数値                         │
│  ● 現在最大級の商用モデルに匹敵                                │
│  ● 学習には数千台のGPU、数ヶ月のトレーニングが必要             │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

**高校生向け解説**：
パラメータは「脳の神経細胞のつながりの強さ」のようなものです。人間の脳には約100兆のシナプス（つながり）がありますが、GPT-4は約1.8兆パラメータ。AIモデルが大きくなるほど「賢く」なる傾向がありますが、その分、学習に膨大な電力とコンピュータ資源が必要です。

---

### 2️⃣ 科学向けAI vs 汎用AI

TPCが目指すのは「科学発見のためのAI」であり、ChatGPTのような汎用AIとは目的が異なります。

```
┌────────────────────────────────────────────────────────────────┐
│                 汎用AI vs 科学向けAI の比較                      │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  【汎用AI（ChatGPT, Claude等）】                                │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  目的: 人間との対話、一般的なタスク支援                   │ │
│  │  訓練データ: インターネット上のテキスト、書籍など          │ │
│  │  評価基準: 人間の満足度、自然な会話                       │ │
│  │  特徴: 幅広い知識、曖昧な質問への対応                     │ │
│  │  課題: 「幻覚」、科学的精度の限界                         │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【科学向けAI（AuroraGPT, TPC等）】                              │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  目的: 科学的発見の加速、仮説生成、実験設計支援            │ │
│  │  訓練データ: 論文、実験データ、シミュレーション結果         │ │
│  │  評価基準: 科学的正確性、再現性、新規性                    │ │
│  │  特徴: ドメイン特化、マルチモーダル（テキスト+数値+画像）   │ │
│  │  目標: 信頼性、検証可能性、透明性                         │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【TPCが解決しようとする課題】                                  │
│                                                                │
│  ❌ 商用AIはクローズドソース（中身がわからない）               │
│  ❌ 科学データでの訓練が不十分                                │
│  ❌ 科学的推論の正確性が保証されない                          │
│  ❌ 再現性・検証可能性が担保されない                          │
│                                                                │
│  ✓ TPCはオープンなモデル開発                                   │
│  ✓ 科学データでのキュレーション・訓練                         │
│  ✓ 信頼性・安全性の評価手法開発                               │
│  ✓ エクサスケール計算資源の共有活用                           │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

**高校生向け解説**：
ChatGPTは「何でも知っている友達」のようなものですが、専門的な科学の質問には間違った答えを自信満々に言うことがあります。科学向けAIは「専門家の科学者」を目指すもので、正確さと根拠が最重要です。

---

### 3️⃣ エクサスケールコンピューティング

1兆パラメータのAIを訓練するには、世界最高レベルのスーパーコンピュータが必要です。

```
┌────────────────────────────────────────────────────────────────┐
│              エクサスケール・スーパーコンピュータ                │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  【エクサ（Exa）とは】                                          │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  1エクサFLOPS = 10^18 FLOPS                               │ │
│  │             = 1,000,000,000,000,000,000 演算/秒           │ │
│  │             = 毎秒100京回の計算                           │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【世界のエクサスケール・スーパーコンピュータ（2024年末時点）】   │
│                                                                │
│  順位  名前       所在地     性能        AI性能               │
│  ────────────────────────────────────────────────────────────  │
│  1位   El Capitan 米LLNL    1.74 EF/s   -                     │
│  2位   Frontier   米ORNL    1.21 EF/s   2.35 EF/s             │
│  3位   Aurora     米ANL     1.01 EF/s   10.6 EF/s ← AI最強   │
│  4位   Fugaku     日理研    0.44 EF/s   -                     │
│                                                                │
│  【Aurora の特徴】                                              │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  ● Intel製GPU（Ponte Vecchio）搭載                       │ │
│  │  ● AI訓練に特化した設計                                  │ │
│  │  ● AuroraGPT（科学向けLLM）を訓練中                       │ │
│  │  ● 10,000ノード以上、63,744 GPU                          │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【Fugaku の特徴】                                              │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  ● Arm A64FX カスタムCPU（富士通製）                      │ │
│  │  ● 2020-2021年に4冠（Top500, HPCG, HPL-AI, Graph500）     │ │
│  │  ● Swallow LLM などの日本語AI開発に活用                   │ │
│  │  ● 次世代「富岳NEXT」を2029年に計画                       │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

**高校生向け解説**：
「エクサスケール」とは、1秒間に100京回（1の後に18個ゼロが並ぶ）の計算ができるレベルです。これは地球上の全人類が100万年かけて電卓で計算するのと同じ量を、たった1秒で処理できる性能です。

---

### 4️⃣ TPCの組織構造と参加機関

TPCは2023年11月に発足した国際的なコンソーシアムです。

```
┌────────────────────────────────────────────────────────────────┐
│                    TPC の組織構造                               │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  【創設パートナー（2023年11月）】                               │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  ● Argonne National Laboratory（米国、リード機関）        │ │
│  │  ● Barcelona Supercomputing Center（スペイン）            │ │
│  │  ● RIKEN（日本）                                          │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【主要参加機関（80組織以上）】                                  │
│                                                                │
│  米国:                                                         │
│  ● Oak Ridge National Lab (ORNL)    ● Brookhaven National Lab │
│  ● Lawrence Berkeley Lab            ● NCSA (Illinois)         │
│  ● Caltech                          ● Allen Institute for AI  │
│                                                                │
│  欧州:                                                         │
│  ● Jülich Supercomputing Centre     ● CEA (フランス)          │
│  ● ETH Zürich                       ● CSC (フィンランド)      │
│  ● Cineca (イタリア)                                          │
│                                                                │
│  アジア太平洋:                                                  │
│  ● RIKEN R-CCS                      ● Institute of Science Tokyo │
│  ● CSIRO (オーストラリア)            ● Flinders University     │
│                                                                │
│  産業界:                                                        │
│  ● NVIDIA                           ● Intel                   │
│  ● Microsoft                        ● Cerebras                │
│  ● Fujitsu                                                    │
│                                                                │
│  【4つの柱】                                                    │
│  1. スケーラブルなモデルアーキテクチャの開発                    │
│  2. 多様な科学データセットの整理・キュレーション                │
│  3. エクサスケールプラットフォーム向けAI技術の最適化             │
│  4. 信頼性・進捗を測る評価手法の開発                           │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

---

### 5️⃣ AuroraGPT - 科学向け基盤モデル

TPCの主要プロジェクトの一つがAuroraGPTです。

```
┌────────────────────────────────────────────────────────────────┐
│                    AuroraGPT プロジェクト                       │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  【概要】                                                       │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  Argonne National Laboratoryが開発中の                    │ │
│  │  科学向け基盤モデル（Foundation Model for Science）       │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【規模】                                                       │
│  ● 目標: 20兆トークン以上の科学テキスト・構造化データ          │
│  ● モデルサイズ: 80億〜4000億以上パラメータ                    │
│  ● 訓練プラットフォーム: Aurora（10,000+ノード）               │
│                                                                │
│  【達成済みマイルストーン】                                     │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  ● 7Bパラメータモデルを2兆トークンで事前学習完了          │ │
│  │  ● 3,200ノードでの分散訓練に成功                          │ │
│  │  ● 持続性能4.11 ExaFLOPS、ピーク5.57 ExaFLOPS達成         │ │
│  │  ● Megatron-DeepSpeed フレームワーク最適化                │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【対象分野】                                                   │
│  ● 生物学・がん研究                                            │
│  ● 化学・材料科学                                              │
│  ● 気候変動・地球科学                                          │
│  ● 物理学・核融合研究                                          │
│                                                                │
│  【データ構成】                                                 │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  テキスト ──→ 科学論文、特許、教科書                     │ │
│  │  コード ───→ 科学計算コード、シミュレーション            │ │
│  │  構造化 ───→ 実験データ、時系列、分子構造                │ │
│  │  画像 ────→ 顕微鏡画像、シミュレーション結果             │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

---

### 6️⃣ Swallow LLM - 日本発の大規模言語モデル

横田理央教授が関わるもう一つの重要プロジェクトです。

```
┌────────────────────────────────────────────────────────────────┐
│                    Swallow LLM プロジェクト                     │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  【概要】                                                       │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  東京科学大学（旧東工大）の岡崎研・横田研が中心となり      │ │
│  │  開発した日本語能力を強化した大規模言語モデル              │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【開発手法】                                                   │
│  ● ベースモデル: Meta社 Llama 2/3                             │
│  ● 語彙拡張: 日本語文字を追加                                 │
│  ● 継続事前学習: 大規模日本語Webコーパスで追加訓練            │
│  ● 訓練基盤: ABCI, TSUBAME, 富岳                               │
│                                                                │
│  【主要バージョン】                                             │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  Swallow (Llama 2ベース): 7B, 13B, 70B                    │ │
│  │  Llama 3 Swallow: 8B, 70B                                 │ │
│  │  Llama 3.3 Swallow 70B v0.4: GPT-4o-mini超えを達成        │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【特徴】                                                       │
│  ● 日本語タスクでの性能が大幅向上                              │
│  ● 継続学習でも英語能力を維持                                  │
│  ● HuggingFaceでオープン公開                                   │
│  ● NEDO支援、AIST ABCIで訓練                                   │
│                                                                │
│  【意義】                                                       │
│  ● 日本語主権AI（Sovereign AI）の実現                          │
│  ● 海外依存からの脱却                                          │
│  ● 日本の研究コミュニティへの貢献                              │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

---

## 📖 発表概要

### 🎯 コンソーシアムの目的

TPCは、**科学的発見のための大規模AIシステムを構築する**という膨大な課題に取り組むため、政府研究所、学術機関、研究機関、産業界の科学者を集めた**グローバルなイニシアチブ**です。

### 📊 期待されるセッション内容

```
┌────────────────────────────────────────────────────────────────┐
│                TPC セッションの主要トピック                      │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  Day 1（1/27）: 技術的進捗とチャレンジ                          │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  ● AuroraGPTの最新進捗報告                               │ │
│  │  ● 各国・機関の大規模AI開発状況                          │ │
│  │  ● データキュレーションの課題と解決策                     │ │
│  │  ● 分散訓練技術の最新動向                                │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  Day 2（1/28）: 応用と将来展望                                  │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │  ● 科学分野への適用事例                                  │ │
│  │  ● 評価手法と信頼性確保                                  │ │
│  │  ● 国際協力のフレームワーク                              │ │
│  │  ● 今後のロードマップ                                    │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
│  【議論のポイント】                                             │
│  ● 商用AIとオープン科学AIの役割分担                            │
│  ● エクサスケール資源の効率的活用                              │
│  ● マルチモーダル（テキスト+数値+画像）対応                    │
│  ● 信頼性・再現性・検証可能性の担保                            │
│  ● 異分野間でのモデル共有・転移学習                            │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

---

## 🔬 技術的詳細

### 🧪 1兆パラメータモデル訓練の課題

| 課題 | 詳細 | 現状（2025年） |
|------|------|----------------|
| **計算資源** | 最低でもエクサスケール級が必要 | Aurora, Frontier等に限定 |
| **訓練時間** | 数ヶ月〜1年の専有使用 | 複数機関での分散が必須 |
| **電力消費** | 数十MW規模 | カーボンフットプリントが課題 |
| **データ品質** | 科学データのキュレーション | 20兆トークン収集が目標 |
| **分散訓練** | 数千GPU間の効率的並列化 | Megatron-DeepSpeedで対応 |
| **評価手法** | 科学的正確性の測定 | 標準ベンチマーク開発中 |

### 📈 TPC25会議の成果（2025年3月、サンノゼ）

- **参加者**: 350名以上の研究者・産業界リーダー・AI専門家
- **主要テーマ**: AI時代の科学的発見
- **合意事項**: オープンな大規模モデル開発の継続
- **課題認識**: 責任あるAI開発の重要性

### 🔍 各国・地域の取り組み

| 国/地域 | 主要プロジェクト | 計算資源 | 特徴 |
|---------|------------------|----------|------|
| **米国** | AuroraGPT | Aurora (1.01 EF) | 科学全般向け |
| **日本** | Swallow, llm-jp | 富岳 (0.44 EF) | 日本語特化 |
| **欧州** | GenAI4EU | LUMI, Leonardo | EU規制対応 |
| **中国** | Kimi K2 | 非公開 | 1兆パラメータ達成 |

---

## 👤 発表者プロフィール

### Rio Yokota（横田理央）

| 項目 | 内容 |
|------|------|
| **現職** | 東京科学大学 学術国際情報センター スーパーコンピューティング研究部門 教授 |
| **兼任** | 理研R-CCS AI for Science基盤モデル研究チーム リーダー |
| **学歴** | 機械工学博士 |
| **専門分野** | 高性能計算、機械学習、線形代数 |

**キャリア**：
- **2007年〜**: GPU最適化研究開始
- **2009年**: Gordon Bell Prize受賞（初のGPUスーパーコンピュータ）
- **2010-2011**: ボストン大学 ポスドク
- **2011-2015**: KAUST（サウジアラビア）研究員
- **現在**: ABCI, TSUBAME, 富岳での大規模LLM訓練をリード

**主要プロジェクト**：
- **Swallow LLM**: 日本語能力を強化したLlama派生モデル
- **llm-jp**: 国立情報学研究所との日本語LLM共同開発
- **ADAC**: 国際HPC協力プロジェクト
- **TPC**: Trillion Parameter Consortium

**国際協力**：
- ORNL, ANL, LLNL, CSC, ETH等の世界トップスパコンセンターと協力
- 理研AIP Khan グループとベイジアン深層学習で協力
- AIST AI研究センターと視覚言語モデルで協力

---

### Charlie Catlett

| 項目 | 内容 |
|------|------|
| **現職** | Argonne National Laboratory シニアコンピュータサイエンティスト |
| **兼任** | University of Chicago Mansueto Institute for Urban Innovation シニアフェロー |
| **学歴** | イリノイ大学アーバナ・シャンペーン校 コンピュータ工学 |
| **専門分野** | 都市コンピューティング、エッジAI、分散システム |

**キャリア**：
- **1985-2000**: NCSA（スーパーコンピューティングセンター）、CTO
- **1992**: Larry Smarrと「メタコンピューティング」論文（グリッド/クラウドの先駆け）
- **2000**: Argonne入所
- **2004-2007**: TeraGrid Initiative ディレクター
- **2007-2011**: Argonne CIO
- **2012**: UrbanCCD（都市計算データセンター）創設

**主要プロジェクト**：
- **Array of Things (AoT)**: NSF資金、シカゴ市のスマートセンサー網
- **SAGE**: ソフトウェア定義センサーネットワーク
- **TPC**: Trillion Parameter Consortium

**受賞**：
- **2016**: Government Technology「25 Doers, Dreamers & Drivers」
- **2019**: Argonne Board of Governors Distinguished Performance Award
- **2025**: HPCwire「HPC People to Watch」

---

## 🔗 関連研究・リソース

### 📄 主要論文・発表

| タイトル | 著者/組織 | 年 | 概要 |
|----------|-----------|-----|------|
| Continual Pre-Training for Cross-Lingual LLM Adaptation | Yokota et al. | 2024 | Swallow LLMの技術論文 |
| The Rapid Growth of AI Foundation Model Usage in Science | arXiv | 2025 | 科学分野でのFM採用動向 |
| AuroraGPT: Foundation Models for Science | ANL | 2024 | AuroraGPTプロジェクト概要 |

### 🛠️ 関連プラットフォーム・モデル

| 名称 | 開発者 | 特徴 |
|------|--------|------|
| **AuroraGPT** | Argonne | 科学向け基盤モデル |
| **Swallow** | 東京科学大学 | 日本語強化LLM |
| **llm-jp** | NII + 複数大学 | 日本語LLM |
| **Kimi K2** | Moonshot AI | 1兆パラメータ中国発 |
| **Prithvi WxC** | NASA | 気象・気候向けFM |

---

## 💭 聴講のポイント

### ❓ 質問候補

| 質問 | 意図 |
|------|------|
| 「商用LLMと科学向けLLMの技術的な違いは何か？」 | 設計思想の理解 |
| 「1兆パラメータモデルの訓練にかかる実際のコストと時間は？」 | 現実的な資源見積もり |
| 「科学向けAIの『正確性』をどう評価・保証するか？」 | 信頼性確保の方法 |
| 「日本の貢献（Swallow, 富岳）はTPCでどう位置づけられているか？」 | 日本の役割 |
| 「オープンモデルと商用モデルの競争・共存はどうなるか？」 | エコシステム予測 |
| 「科学者がAIを使う際の課題と支援は？」 | ユーザー視点 |

### 🏭 マツダAI駆動開発への示唆

| 示唆 | 詳細 | 適用場面 |
|------|------|----------|
| **科学向けAIの活用** | 材料探索、シミュレーション加速にTPCモデル活用 | 新素材開発、軽量化研究 |
| **日本語LLM活用** | Swallowを社内文書処理・ナレッジ管理に適用 | 技術文書検索、FAQ自動化 |
| **分散訓練技術** | 自社データで専用モデルを効率的に訓練 | 品質予測モデル開発 |
| **国際協力参加** | TPCへの参加・データ提供でAI技術力向上 | R&D戦略 |
| **オープンモデル戦略** | 商用ベンダー依存からの脱却 | AIガバナンス |
| **マルチモーダル対応** | テキスト+CADデータ+シミュレーション結果の統合 | 設計支援AI |

---

## 📅 関連セッション（同カンファレンス内）

| セッション名 | 日時 | 関連度 | 備考 |
|-------------|------|--------|------|
| Keynote: AI as a Scientist | 1/28 09:00-09:45 | ⭐⭐⭐⭐⭐ | 北野宏明氏、ノーベルチューリングチャレンジ |
| R-CCS International Symposium | 1/28 11:00-17:50 | ⭐⭐⭐⭐⭐ | 富岳NEXT、AI for Science |
| HANAMI (EU-Japan Alliance) | 1/27 11:30-17:00 | ⭐⭐⭐⭐ | 日欧HPC-AI協力 |
| Societal Impact of HPC and AI | 1/28 11:00-17:00 | ⭐⭐⭐⭐ | 社会へのインパクト |
| Paper Track 2: Using AI in HPC | 1/27 11:30-12:30 | ⭐⭐⭐ | ChatMPI等 |

---

## 📚 参考資料

### 📖 公式サイト・ドキュメント

- [Trillion Parameter Consortium | Argonne](https://www.anl.gov/cels/trillion-parameter-consortium)
- [AuroraGPT Project](https://auroragpt.anl.gov/)
- [TPC 公式サイト](https://tpc.dev/)
- [Swallow LLM](https://swallow-llm.github.io/)

### 🌐 Webリソース

- [YOKOTA Laboratory](https://www.rio.gsic.titech.ac.jp/en/)
- [Charlie Catlett | Argonne](https://www.anl.gov/profile/charles-edward-catlett)
- [Aurora Supercomputer | ALCF](https://www.alcf.anl.gov/aurora)
- [TOP500 List](https://top500.org/)

### 💻 コード・モデル

- [tokyotech-llm (Swallow) | HuggingFace](https://huggingface.co/tokyotech-llm)
- [llm-jp | HuggingFace](https://huggingface.co/llm-jp)

---

## 📖 用語集（高校生向け解説付き）

| 用語 | 読み方 | 説明 |
|------|--------|------|
| **TPC** | ティーピーシー | Trillion Parameter Consortium。1兆パラメータ規模の科学向けAIを開発する国際コンソーシアム。80以上の機関が参加。 |
| **パラメータ** | - | AIモデルの学習によって調整される数値。脳の神経細胞のつながりの強さのようなもの。数が多いほど複雑なパターンを学習できる。 |
| **1兆（Trillion）** | - | 1,000,000,000,000（10^12）。日本語では「1兆」、英語では「Trillion」。GPT-4は約1.8兆パラメータと推定。 |
| **LLM** | エルエルエム | Large Language Model（大規模言語モデル）。ChatGPTのように大量のテキストで学習したAI。 |
| **基盤モデル** | きばんモデル | Foundation Model。様々なタスクに転用できる汎用的な大規模AI。特定タスク用のモデルの「土台」になる。 |
| **エクサスケール** | - | 1秒間に10^18回（100京回）の計算ができるレベル。現在の最高性能スーパーコンピュータの水準。 |
| **FLOPS** | フロップス | Floating Point Operations Per Second。1秒間に何回の小数計算ができるかの単位。1 ExaFLOPS = 10^18 FLOPS。 |
| **Aurora** | オーロラ | 米国アルゴンヌ国立研究所のエクサスケールスーパーコンピュータ。AI性能で世界最強（10.6 ExaFLOPS）。 |
| **Frontier** | フロンティア | 米国オークリッジ国立研究所のスパコン。一般計算性能で世界1位（1.21 ExaFLOPS）。 |
| **富岳** | ふがく | 理化学研究所のスーパーコンピュータ。2020-2021年に世界4冠達成。Arm CPUを採用。 |
| **AuroraGPT** | オーロラジーピーティー | Argonneが開発中の科学向け基盤モデル。生物学、化学、気候など多分野をカバー。 |
| **Swallow** | スワロー | 東京科学大学が開発した日本語能力を強化したLLM。Llamaベース。「ツバメ」の意味。 |
| **継続事前学習** | けいぞくじぜんがくしゅう | Continual Pre-training。既存モデルに追加データで学習を続けること。言語能力の強化に使われる。 |
| **トークン** | - | AIが処理するテキストの最小単位。英語では1単語≒1トークン、日本語では1文字≒1トークン程度。 |
| **分散訓練** | ぶんさんくんれん | 複数のGPU/コンピュータを使って並列にモデルを訓練する技術。大規模モデルには必須。 |
| **Megatron-DeepSpeed** | メガトロンディープスピード | NVIDIAとMicrosoftが開発した大規模モデル訓練フレームワーク。数千GPUでの効率的な訓練を可能にする。 |
| **キュレーション** | - | データを収集・整理・品質管理すること。科学データは誤りや重複があるため、丁寧な整理が必要。 |
| **マルチモーダル** | - | テキスト、画像、音声など複数の種類のデータを扱えること。科学では数値データや分子構造も重要。 |
| **オープンソース** | - | ソースコードや設計が公開されており、誰でも自由に利用・改変できること。科学の透明性に重要。 |
| **クローズドソース** | - | ソースコードが非公開のこと。ChatGPTなど商用AIの多くがこれ。中身がわからないため科学には不向き。 |
| **信頼性** | しんらいせい | AIの出力が正確で一貫していること。科学AIでは特に重要。間違った仮説を信じてしまうリスクがある。 |
| **再現性** | さいげんせい | 同じ条件で実験すれば同じ結果が得られること。科学の基本原則。AIでも保証が求められる。 |
| **スケーリング則** | - | AIモデルは大きくすれば性能が上がるという経験則。ただし計算コストも上がる。 |
| **転移学習** | てんいがくしゅう | ある分野で学習したモデルを別の分野に適用すること。効率的なモデル開発に重要。 |
| **Gordon Bell Prize** | ゴードンベルプライズ | スーパーコンピューティング分野の最高賞の一つ。毎年SCカンファレンスで授与。 |
| **ABCI** | エービーシーアイ | AI Bridging Cloud Infrastructure。産総研が運用するAI研究用スパコン。Swallowの訓練に使用。 |
| **TSUBAME** | ツバメ | 東京科学大学が運用するスーパーコンピュータ。日本のGPUスパコンの先駆け。 |
| **主権AI** | しゅけんエーアイ | Sovereign AI。自国でAI基盤を持つこと。海外依存からの脱却、データ主権の確保が目的。 |

---

*作成日: 2025-12-25*
*SCA/HPC Asia 2026 事前勉強資料*
