# 📚 The 8th R-CCS International Symposium
## SCA/HPC Asia 2026 事前勉強資料

---

## 📋 発表情報

| 項目 | 内容 |
|------|------|
| **セッション名** | The 8th R-CCS International Symposium |
| **日時** | 2026年1月28日（水）11:00 - 17:50 |
| **会場** | グランキューブ大阪（詳細TBA） |
| **主催** | RIKEN Center for Computational Science (R-CCS) |
| **オーガナイザー** | Mitsunori Ikeguchi（池口満徳）, R-CCS |
| **関連度** | ⭐⭐⭐⭐⭐（日本のHPC/AI戦略の最前線を知る必須イベント） |

### プログラム概要

| 時間 | 内容 | 議長 |
|------|------|------|
| 11:00-11:10 | Opening & MOU Signing Ceremony | Mitsunori Ikeguchi |
| 11:10-12:30 | Session-1: FugakuNEXT: HPC Applications | Yasumichi Aoki |
| 12:30-13:30 | Lunch Break | - |
| 13:30-15:00 | Session-2: FugakuNEXT: AI for Science | Rio Yokota, Mohamed Wahib |
| 15:00-15:30 | Break | - |
| 15:30-16:20 | Overview | Satoshi Matsuoka |
| 16:20-17:50 | Session-3: FugakuNEXT: Systems | Masaaki Kondo |
| 17:50 | Closing | Mitsunori Ikeguchi |
| 18:15-20:00 | Reception | - |

### 公式サイト

https://www.r-ccs.riken.jp/R-CCS-Symposium/2026/

---

## 🎯 この発表を理解するための前提知識

### 1️⃣ RIKEN R-CCS（理化学研究所 計算科学研究センター）とは

**概念**: 日本最大のスーパーコンピューティング研究機関で、「富岳」の運営母体です。

```
R-CCS（理研計算科学研究センター）:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【所在地】神戸市ポートアイランド                          │
│                                                             │
│  【前身】                                                   │
│  ・理研 計算科学研究機構（AICS）→ 京コンピュータ運営      │
│  ・2018年に R-CCS へ改組                                   │
│                                                             │
│  【主な活動】                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ ・スーパーコンピュータ「富岳」の運営                 │   │
│  │ ・次世代スパコン「FugakuNEXT」の研究開発             │   │
│  │ ・計算科学・AI・量子コンピューティング研究           │   │
│  │ ・国内外の研究機関との連携                           │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  【スタッフ】約1,000名以上                                  │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**なぜ重要か**: R-CCSは日本のHPC戦略の中核であり、富岳からFugakuNEXTへの移行を主導しています。

---

### 2️⃣ 富岳（Fugaku）スーパーコンピュータ

**概念**: 2020年から稼働している日本のフラッグシップスーパーコンピュータです。

```
富岳の基本情報:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【名前の由来】富士山の別名「富嶽」                        │
│                                                             │
│  【稼働開始】2021年3月（共用開始）                         │
│                                                             │
│  【システム構成】                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ ノード数:    158,976ノード                           │   │
│  │ CPU:         Fujitsu A64FX（Arm v8.2-A + SVE）       │   │
│  │ 総コア数:    約800万コア                             │   │
│  │ メモリ:      約5 PB（HBM2）                          │   │
│  │ ストレージ:  150 PB以上                              │   │
│  │ 消費電力:    約30 MW                                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  【接続】Tofu Interconnect D（6次元メッシュ/トーラス）     │
│  ケーブル総延長: 約900 km                                   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**歴史的成果**:
- 2020年6月: TOP500で世界1位を獲得
- 史上初めて4つの主要ベンチマーク（TOP500, HPCG, HPL-AI, Graph500）で同時1位
- 2022年5月: Frontierに1位を譲るも、現在もトップクラスの性能を維持

---

### 3️⃣ A64FXプロセッサ

**概念**: 富岳の心臓部である、富士通開発のArmベースプロセッサです。

```
A64FXの革新性:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【世界初の機能】                                           │
│  ・Scalable Vector Extension（SVE）実装                    │
│  ・可変長ベクトル処理（128〜2048ビット）                   │
│  ・富岳では512ビット幅で使用                               │
│                                                             │
│  【構成】                                                   │
│  ┌────────────────────────────────────────────┐            │
│  │  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐          │            │
│  │  │Core │ │Core │ │Core │ │Core │ ×12      │ CMG 0     │
│  │  └─────┘ └─────┘ └─────┘ └─────┘          │            │
│  │           ↓ L2キャッシュ(8MB)              │            │
│  ├────────────────────────────────────────────┤            │
│  │  CMG 1 (12コア + L2 8MB)                   │            │
│  ├────────────────────────────────────────────┤            │
│  │  CMG 2 (12コア + L2 8MB)                   │            │
│  ├────────────────────────────────────────────┤            │
│  │  CMG 3 (12コア + L2 8MB)                   │            │
│  └────────────────────────────────────────────┘            │
│                    ↓                                        │
│  ┌────────────────────────────────────────────┐            │
│  │         HBM2 (32GB, 1024 GB/s)             │            │
│  └────────────────────────────────────────────┘            │
│                                                             │
│  計48コア + 4アシスタントコア                               │
│  ピーク性能: 3.4 TFLOPS (FP64)                              │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**SVE（Scalable Vector Extension）の特徴**:
- ベクトル長がソフトウェアで抽象化
- 異なるハードウェアでも同じプログラムが動作
- 将来の拡張に対応可能

---

### 4️⃣ FugakuNEXT（富岳の次世代機）

**概念**: 2030年頃の稼働を目指す、日本の次世代フラッグシップスーパーコンピュータです。

```
FugakuNEXT計画:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【目標】ゼタスケール（1,000エクサFLOPS = 1 ZFLOPS）       │
│                                                             │
│  現在のトップ（Frontier）: 約1.2 EFLOPS                    │
│  FugakuNEXT目標: 約600 EFLOPS（FP8）〜 1 ZFLOPS           │
│  → 現在の約1,000倍の性能！                                 │
│                                                             │
│  【予算】約1,100億円（7.4億ドル）                          │
│                                                             │
│  【タイムライン】                                           │
│  2022年: 実現可能性調査開始                                 │
│  2025年: 基本設計契約（富士通）                             │
│  2026年2月: 基本設計完了予定                                │
│  2030年頃: 稼働開始予定                                     │
│                                                             │
│  【パートナー】                                             │
│  ・RIKEN: 運営・研究                                        │
│  ・Fujitsu: MONAKA-X CPU開発                               │
│  ・NVIDIA: GPU・NVLink Fusion提供                          │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

### 5️⃣ FUJITSU-MONAKA（モナカ）プロセッサ

**概念**: FugakuNEXTに搭載予定の、富士通の次世代Armプロセッサです。

```
FUJITSU-MONAKAの特徴:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【アーキテクチャ】Armv9-A + SVE2 + CCA                    │
│                                                             │
│  【コア数】144コア（2ソケットで288コア/ノード）            │
│                                                             │
│  【製造プロセス】                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 計算チップレット: TSMC 2nm                           │   │
│  │ SRAM/IOダイ:     TSMC 5nm                            │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  【3Dチップレット構造】                                     │
│                                                             │
│      ┌───────────┬───────────┬───────────┬───────────┐    │
│      │36コア(2nm)│36コア(2nm)│36コア(2nm)│36コア(2nm)│    │
│      └─────┬─────┴─────┬─────┴─────┬─────┴─────┬─────┘    │
│            │HCB接続    │HCB接続    │HCB接続    │          │
│      ┌─────┴─────┬─────┴─────┬─────┴─────┬─────┴─────┐    │
│      │SRAM(5nm)  │SRAM(5nm)  │SRAM(5nm)  │SRAM(5nm)  │    │
│      └───────────┴───────────┴───────────┴───────────┘    │
│                          │                                  │
│                   ┌──────┴──────┐                          │
│                   │  IO Die(5nm) │                          │
│                   └──────────────┘                          │
│                                                             │
│  HCB = Hybrid Copper Bonding（銅ハイブリッド接合）          │
│                                                             │
│  【メモリ】DDR5 12チャネル                                  │
│  【I/O】PCIe 6.0 + CXL 3.0                                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**FugakuNEXT用変種: MONAKA-X**
- NVIDIA GPUと連携するための拡張版
- NVLink Fusionで高速GPU接続

---

### 6️⃣ NVLink Fusion

**概念**: NVIDIA以外のCPU/アクセラレータをNVLinkで接続可能にする技術です。

```
NVLink Fusionの仕組み:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【従来】NVLinkはNVIDIA製品専用                            │
│                                                             │
│  NVIDIA GPU ←──NVLink──→ NVIDIA GPU ✓                      │
│  Fujitsu CPU ←──NVLink──→ NVIDIA GPU ✗                     │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  【NVLink Fusion】サードパーティに開放                      │
│                                                             │
│  ┌──────────────┐      ┌──────────────┐                    │
│  │ MONAKA-X CPU │      │ NVIDIA GPU   │                    │
│  │              │      │              │                    │
│  │ ┌──────────┐ │      │ ┌──────────┐ │                    │
│  │ │NVLink 5  │ │←────→│ │NVLink 5  │ │                    │
│  │ │Chiplet   │ │1.8TB/s│ │          │ │                    │
│  │ └──────────┘ │      │ └──────────┘ │                    │
│  └──────────────┘      └──────────────┘                    │
│                                                             │
│  NVLinkチップレットをCPUに統合することで接続可能に          │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**性能**:
- NVLink 5: 1.8 TB/s（双方向）
- PCIe Gen5の14倍の帯域幅

---

### 7️⃣ AI for Science（科学のためのAI）

**概念**: AIを科学研究の加速に活用するパラダイムです。

```
AI for Scienceの概念:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【従来の科学研究】                                         │
│                                                             │
│  観察 → 仮説 → 実験 → 分析 → 理論                          │
│   ↑       ↓                                                │
│   └───────┘ (人間による繰り返し)                           │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  【AI for Science】                                         │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                    AI/ML                             │   │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐             │   │
│  │  │仮説生成  │ │実験計画  │ │データ分析│             │   │
│  │  └──────────┘ └──────────┘ └──────────┘             │   │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐             │   │
│  │  │シミュ    │ │論文執筆  │ │発見の    │             │   │
│  │  │レーション│ │支援      │ │自動検証  │             │   │
│  │  └──────────┘ └──────────┘ └──────────┘             │   │
│  └─────────────────────────────────────────────────────┘   │
│              ↓                                              │
│       科学的発見の大幅な加速                                │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**R-CCSでの取り組み**:
1. **Fugaku-LLM**: 富岳で学習した日本語大規模言語モデル
2. **Swallow**: 横田理央教授チームの日本語LLM
3. **基盤モデル研究**: AI for Science Foundation Model Research Team

---

### 8️⃣ 基盤モデル（Foundation Model）

**概念**: 大規模データで事前学習され、様々なタスクに適用可能なAIモデルです。

```
基盤モデルの概念:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【従来のAIモデル】タスクごとに専用モデル                   │
│                                                             │
│  タスクA → 専用モデルA                                      │
│  タスクB → 専用モデルB                                      │
│  タスクC → 専用モデルC                                      │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  【基盤モデル】1つのモデルを多目的に活用                    │
│                                                             │
│           ┌─────────────────────────────────┐              │
│           │      大規模基盤モデル           │              │
│           │  (GPT, BERT, AlphaFold等)      │              │
│           └─────────────────────────────────┘              │
│                  ↓ ファインチューニング                     │
│        ┌─────────┼─────────┐                               │
│        ↓         ↓         ↓                               │
│    タスクA    タスクB    タスクC                            │
│                                                             │
│  科学分野での例:                                            │
│  ・タンパク質構造予測（AlphaFold）                         │
│  ・気象予測（Aurora）                                       │
│  ・分子設計                                                 │
│  ・材料探索                                                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

### 9️⃣ HPC-AI融合

**概念**: 従来の数値シミュレーション（HPC）とAI/機械学習を統合するアプローチです。

```
HPC-AI融合:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【従来のHPC】物理法則に基づく数値シミュレーション          │
│                                                             │
│  偏微分方程式 → 離散化 → 数値計算 → 結果                    │
│                                                             │
│  利点: 物理的に正確、説明可能                               │
│  欠点: 計算コストが高い、複雑な系は困難                     │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  【AI/ML】データ駆動型予測                                  │
│                                                             │
│  学習データ → ニューラルネット → 予測                       │
│                                                             │
│  利点: 高速、パターン認識に強い                             │
│  欠点: 物理法則を無視する可能性、説明困難                   │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  【HPC-AI融合】両者の長所を組み合わせ                       │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  物理シミュレーション                                │   │
│  │      ↕ データ生成・補完                              │   │
│  │  AIサロゲートモデル                                  │   │
│  │      ↕ 高速近似・最適化                              │   │
│  │  結果の物理的検証                                    │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**FugakuNEXTでの実現**:
- CPU（MONAKA-X）: 物理シミュレーション
- GPU（NVIDIA）: AI/ML処理
- NVLink Fusionで高速連携

---

### 🔟 量子-HPC ハイブリッド

**概念**: 量子コンピュータとスーパーコンピュータを連携させるアプローチです。

```
量子-HPCハイブリッド:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  【RIKENの取り組み】                                        │
│                                                             │
│  2024年4月: IBMの次世代量子システムを富岳に統合する        │
│             契約を発表                                      │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                                                       │   │
│  │  ┌───────────────┐      ┌───────────────┐           │   │
│  │  │ 量子コンピュータ │←───→│  富岳（HPC）  │           │   │
│  │  │  (IBM Quantum)  │      │               │           │   │
│  │  └───────────────┘      └───────────────┘           │   │
│  │         ↓                        ↓                    │   │
│  │  量子アルゴリズム          古典アルゴリズム           │   │
│  │  ・最適化問題              ・大規模シミュレーション   │   │
│  │  ・量子化学計算            ・データ処理               │   │
│  │                                                       │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  【目標】                                                   │
│  ・量子-古典ハイブリッドアルゴリズムの開発                 │
│  ・材料科学、創薬などへの応用                              │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 📖 発表概要

### 🎯 シンポジウムの目的

本シンポジウムは、「富岳」から「FugakuNEXT」への展望と、AI技術を含む将来志向のコンピュータサイエンスおよび計算科学に関する最先端の学術研究について議論することを目的としています。

### 📊 期待される発表内容

**Session 1: FugakuNEXT: HPC Applications（11:10-12:30）**
- 次世代スパコンで実現するアプリケーション
- 計算科学分野での期待される成果
- 議長: Yasumichi Aoki（青木保道）

**Session 2: FugakuNEXT: AI for Science（13:30-15:00）**
- AI駆動型科学研究の最前線
- 基盤モデルの科学応用
- 議長: Rio Yokota（横田理央）、Mohamed Wahib

**Overview（15:30-16:20）**
- FugakuNEXTプロジェクト全体像
- 発表者: Satoshi Matsuoka（松岡聡）R-CCS所長

**Session 3: FugakuNEXT: Systems（16:20-17:50）**
- システムアーキテクチャの詳細
- MONAKA-X CPU、NVLink Fusion、電力効率
- 議長: Masaaki Kondo（近藤正章）

---

## 🔬 技術的詳細

### 🧪 FugakuNEXTの技術仕様（予定）

| 項目 | 富岳（現行） | FugakuNEXT（計画） |
|------|-------------|-------------------|
| **CPU** | A64FX (7nm) | MONAKA-X (2nm) |
| **GPU** | なし | NVIDIA製（詳細未定） |
| **コア数/CPU** | 48+4 | 144 |
| **ベクトル幅** | 512ビット (SVE) | TBD (SVE2) |
| **CPU-GPU接続** | - | NVLink Fusion |
| **メモリ** | HBM2 32GB | DDR5 + HBM（予定） |
| **ピーク性能** | 442 PFLOPS (FP64) | 600+ EFLOPS (FP8) |
| **電力** | 約30 MW | 約40 MW（目標） |
| **稼働開始** | 2021年3月 | 2030年頃 |

### 📈 性能向上の見込み

```
富岳からFugakuNEXTへの性能向上:
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│  FP64性能:  約10倍                                         │
│  │████████████████████████████████│                        │
│                                                             │
│  FP8性能（AI）: 約1,000倍以上                              │
│  │████████████████████████████████████████████████████│    │
│                                                             │
│  電力あたり性能: 約25倍                                    │
│  │████████████████████│                                    │
│                                                             │
│  ※ 40MW電力枠内での達成を目標                              │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 🔍 主要な技術課題

| 課題 | アプローチ |
|------|-----------|
| 電力効率 | 2nm製造、3Dチップレット、超低電圧動作 |
| CPU-GPU連携 | NVLink Fusionによる高帯域接続 |
| AI-HPC融合 | 統合プログラミング環境、ワークフロー自動化 |
| ソフトウェア継承 | 富岳アプリの移植性確保、Arm SVE2互換 |
| 冷却 | 空冷維持（MONAKA）、ただしGPUは液冷の可能性 |

---

## 👤 主要発表者プロフィール

### Satoshi Matsuoka（松岡聡）- R-CCS所長

| 項目 | 内容 |
|------|------|
| **現職** | RIKEN R-CCS 所長（2018年〜） |
| **前職** | 東京工業大学 教授 |
| **学位** | 東京大学 博士（1993年） |
| **専門** | 高性能計算、並列分散システム |

**主な受賞歴**:
| 年 | 賞名 |
|----|------|
| 2011, 2021 | ACM Gordon Bell Prize（2回受賞） |
| 2014 | IEEE Sidney Fernbach Award |
| 2022 | IEEE Seymour Cray Computer Engineering Award |
| 2022 | 紫綬褒章 |

**特記事項**:
- 富岳開発の総責任者
- TSUBAME シリーズの設計者
- 学生時代にNintendo向けゲーム開発（岩田聡氏と協働）

---

### Rio Yokota（横田理央）- AI for Science研究チームリーダー

| 項目 | 内容 |
|------|------|
| **現職** | 東京科学大学（旧東工大）教授、R-CCS チームリーダー |
| **専門** | HPC、機械学習、線形代数 |
| **称号** | ACM Gordon Bell Prize (2009) |

**主な業績**:
- Fugaku-LLM（富岳での日本語LLM学習）リーダー
- Swallow、LLM-jp共同開発者
- 2007年からGPU最適化研究

---

### Mohamed Wahib - 高性能AI システム研究チームリーダー

| 項目 | 内容 |
|------|------|
| **現職** | R-CCS 高性能AIシステム研究チームリーダー |
| **前職** | AIST/東工大 上級研究員 |
| **学位** | 北海道大学 博士 |
| **受賞** | R&D 100 Award (2022, Flash-X) |

---

### Masaaki Kondo（近藤正章）- 次世代HPCインフラ開発ディビジョン長

| 項目 | 内容 |
|------|------|
| **現職** | R-CCS 次世代HPCインフラ開発ディビジョン長、慶應義塾大学教授 |
| **専門** | コンピュータアーキテクチャ、電力効率、冷却 |
| **経験** | 京コンピュータ、富岳のアーキテクチャ開発に参画 |

---

## 🔗 関連研究

### 📄 主要論文

| 論文タイトル | 著者 | 発表 | 概要 |
|-------------|------|------|------|
| Fugaku and A64FX: the First Exascale Supercomputer and its Innovative Arm CPU | Sato et al. | SC'21 | 富岳とA64FXの技術詳細 |
| The Supercomputer "Fugaku" and Arm-SVE enabled A64FX processor | Kodama et al. | CF'20 | SVEの実装と性能 |
| Scaling Deep Learning Workloads Beyond Memory Capacity | Wahib et al. | SC'20 | 大規模深層学習 |

### 🛠️ 関連プロジェクト・ツール

| 名称 | 概要 | URL |
|------|------|-----|
| **Fugaku-LLM** | 富岳で学習した日本語LLM | - |
| **Swallow** | 日本語LLM（横田研） | https://swallow-llm.github.io/ |
| **Virtual Fugaku** | 富岳ソフトウェアのクラウド展開 | https://www.r-ccs.riken.jp/en/fugaku/virtual-fugaku/ |
| **Flash-X** | マルチフィジックスシミュレーションソフト | https://github.com/Flash-X/Flash-X |

---

## 💭 聴講のポイント

### ❓ 質問候補

| 質問 | 意図 |
|------|------|
| FugakuNEXTでのAI-HPCワークロード分離・統合の方針は？ | システム設計思想の理解 |
| MONAKA-XとNVIDIA GPUの具体的な連携方式は？ | NVLink Fusionの実装詳細 |
| 富岳アプリケーションのFugakuNEXT移行計画は？ | ソフトウェア継続性 |
| 産業界との連携モデルは？ | 企業活用の可能性 |
| 量子-HPCハイブリッドの進捗は？ | 新技術の実用化見通し |
| 40MW電力枠でゼタスケールを達成する技術的課題は？ | エネルギー効率の実現性 |

### 🏭 マツダAI駆動開発への示唆

| 観点 | 示唆 |
|------|------|
| **計算資源活用** | 富岳・FugakuNEXTへのジョブ投入で自社にない計算能力を活用可能 |
| **AI-HPC融合** | シミュレーション（CFD、構造解析）とAIを組み合わせた設計最適化 |
| **基盤モデル活用** | 科学基盤モデルの自動車設計・材料開発への適用 |
| **産学連携** | R-CCSとの共同研究で最先端技術へのアクセス |
| **人材交流** | R-CCSへの研究員派遣や共同プロジェクトでスキル獲得 |
| **将来投資判断** | 2030年のFugakuNEXT稼働を見据えた計算戦略策定 |

---

## 📅 関連セッション（同カンファレンス内）

| セッション名 | 日時 | 関連性 |
|-------------|------|-------|
| **Keynote: Quo Vadis Computer Architecture** | 1/28 09:45-10:30 | アーキテクチャ進化の文脈 |
| **Keynote: Ultra Ethernet for AI and HPC** | 1/27 09:30-10:15 | ネットワーク技術（Torsten Hoefler） |
| **TPC: Trillion Parameter Consortium** | 1/27-28 | 大規模AI研究連携（横田理央共同主催） |
| **HANAMI** | 1/27 11:30-17:00 | 日欧HPC協力 |
| **Vision and Strategy** | 1/27-28 | 世界のHPCセンター動向 |
| **Paper Track 8: Accelerators in Practice** | 1/28 11:00-12:30 | アクセラレータ実践事例 |

---

## 📚 参考資料

### 📖 論文・技術文書

- [Fujitsu A64FX技術レビュー](https://www.fujitsu.com/global/about/resources/publications/technicalreview/2020-03/article03.html)
- [FUJITSU-MONAKA技術概要](https://www.fujitsu.com/global/about/research/technology/fujitsu-monaka/)
- [FugakuNEXTプレスリリース（Fujitsu）](https://www.fujitsu.com/global/about/resources/news/press-releases/2025/0618-01.html)

### 🌐 Webリソース

- [RIKEN R-CCS 公式](https://www.r-ccs.riken.jp/en/)
- [富岳公式ページ](https://www.r-ccs.riken.jp/en/fugaku/)
- [R-CCS国際シンポジウム2026](https://www.r-ccs.riken.jp/R-CCS-Symposium/2026/)
- [NVIDIA FugakuNEXTブログ](https://blogs.nvidia.com/blog/fugakunext/)
- [横田研究室](https://www.rio.gsic.titech.ac.jp/en/)

### 💻 GitHub

- [Flash-X](https://github.com/Flash-X/Flash-X)
- [Swallow LLM](https://github.com/swallow-llm)
- [LLM-jp](https://github.com/llm-jp)

---

## 📖 用語集（高校生向け解説付き）

| 用語 | 読み方 | 説明 |
|------|--------|------|
| **R-CCS** | アールシーシーエス | RIKEN Center for Computational Science（理研計算科学研究センター）。神戸にある日本最大のスパコン研究機関。「計算で科学を進める」ためのセンター。 |
| **RIKEN** | りけん | 理化学研究所。日本最大の総合研究機関で、1917年設立。ノーベル賞受賞者も輩出。 |
| **富岳** | ふがく | 日本のスーパーコンピュータ。富士山の別名から命名。2020年に世界最速を達成。約16万ノードで構成。 |
| **FugakuNEXT** | ふがくねくすと | 富岳の後継機として2030年頃稼働予定の次世代スパコン。現在の約1,000倍の性能を目指す。 |
| **ゼタスケール** | ぜたすけーる | 1秒間に10の21乗（1,000エクサ）回の計算ができる性能。現在のトップスパコンの約1,000倍。 |
| **エクサスケール** | えくさすけーる | 1秒間に10の18乗回の計算ができる性能。米国Frontierが2022年に初達成。 |
| **A64FX** | えーろくよんえふえっくす | 富岳に搭載された富士通製CPU。Armアーキテクチャで世界初のSVE実装。 |
| **MONAKA** | もなか | 富士通の次世代Armプロセッサ。和菓子の最中が名前の由来。2nm製造プロセス採用予定。 |
| **SVE** | エスブイイー | Scalable Vector Extension。Armのベクトル拡張命令。長さを自由に設定できるのが特徴。 |
| **SVE2** | エスブイイーツー | SVEの第2世代。セキュリティ機能（CCA）なども追加。MONAKAで採用予定。 |
| **Arm** | あーむ | 英国発のCPUアーキテクチャ設計会社。スマホ、タブレット、そして今やスパコンでも使用。省電力が特徴。 |
| **チップレット** | ちっぷれっと | 複数の小さなチップを組み合わせて1つの大きなプロセッサを作る技術。レゴブロックのように部品を組み合わせる。 |
| **NVLink** | エヌブイリンク | NVIDIA開発の高速接続技術。複数のGPUやCPUを超高速で接続。 |
| **NVLink Fusion** | エヌブイリンクフュージョン | NVIDIA以外のチップもNVLinkで接続可能にする技術。2025年発表。 |
| **HBM** | エイチビーエム | High Bandwidth Memory。超広帯域メモリ。CPUやGPUのすぐ横に積層して配置。 |
| **Tofu Interconnect** | とうふ | 富岳のネットワーク技術。「Torus Fusion」の略で、豆腐にちなんで命名。6次元メッシュ構造。 |
| **AI for Science** | えーあいふぉーさいえんす | AIを使って科学研究を加速する取り組み。仮説生成から実験、論文執筆までAIが支援。 |
| **基盤モデル** | きばんもでる | 大量のデータで学習した汎用AIモデル。GPT、BERTなどが代表例。様々なタスクに応用可能。 |
| **Fugaku-LLM** | ふがくえるえるえむ | 富岳で学習された日本語大規模言語モデル。横田理央教授チームが開発。 |
| **LLM** | エルエルエム | Large Language Model（大規模言語モデル）。ChatGPTなどの基盤技術。 |
| **HPC** | エイチピーシー | High Performance Computing（高性能計算）。スパコンを使った大規模計算。 |
| **Gordon Bell Prize** | ごーどんべるぷらいず | スパコン応用の最高峰の賞。松岡聡所長は2回受賞。 |
| **Sidney Fernbach Award** | しどにーふぁーんばっくあわーど | HPCへの貢献を称えるIEEE賞。松岡聡所長が2014年受賞。 |
| **Seymour Cray Award** | しーもあくれいあわーど | スパコンアーキテクチャへの貢献を称えるIEEE賞。松岡聡所長が2022年受賞。 |
| **量子-HPCハイブリッド** | りょうし-えいちぴーしーはいぶりっど | 量子コンピュータとスパコンを連携させるアプローチ。両者の長所を組み合わせる。 |
| **PFLOPS** | ペタフロップス | 1秒間に10の15乗回の浮動小数点演算。富岳は約440 PFLOPS。 |
| **EFLOPS** | エクサフロップス | 1秒間に10の18乗回の浮動小数点演算。1,000 PFLOPS。 |
| **ZFLOPS** | ゼタフロップス | 1秒間に10の21乗回の浮動小数点演算。1,000 EFLOPS。FugakuNEXTの目標。 |
| **FP64** | エフピーろくじゅうよん | 64ビット浮動小数点数。科学計算の標準精度。 |
| **FP8** | エフピーはち | 8ビット浮動小数点数。AI推論向けの低精度形式。 |
| **ノード** | のーど | スパコンを構成する個々のコンピュータ単位。富岳は約16万ノード。 |
| **MOU** | エムオーユー | Memorandum of Understanding（覚書）。組織間の協力合意文書。 |

---

*作成日: 2025-12-25*
*SCA/HPC Asia 2026 事前勉強資料*
